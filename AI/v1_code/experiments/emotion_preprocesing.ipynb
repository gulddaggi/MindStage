{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66da1deb",
   "metadata": {},
   "source": [
    "## ë°ì´í„° êµ¬ì¡°\n",
    "\n",
    "```text\n",
    "dataSet\n",
    "â”œâ”€â”€ info                        â† ë©´ì ‘ ë©”íƒ€ë°ì´í„°\n",
    "â”‚   â”œâ”€â”€ date                    : ë‚ ì§œ (YYYYMMDD)\n",
    "â”‚   â”œâ”€â”€ occupation              : ì§ë¬´ ì½”ë“œ (ì˜ˆ: BM, SM ë“±)\n",
    "â”‚   â”œâ”€â”€ channel                 : ì¸í„°ë·° ë°©ì‹ (MOCK, REAL ë“±)\n",
    "â”‚   â”œâ”€â”€ place                   : ì¥ì†Œ (ONLINE, OFFLINE ë“±)\n",
    "â”‚   â”œâ”€â”€ gender                  : ì„±ë³„ (MALE / FEMALE)\n",
    "â”‚   â”œâ”€â”€ ageRange                : ì—°ë ¹ëŒ€ (ì˜ˆ: \"45-54\")\n",
    "â”‚   â””â”€â”€ experience              : ê²½ë ¥ êµ¬ë¶„ (EXPERIENCED / INEXPERIENCED)\n",
    "â”‚\n",
    "â”œâ”€â”€ question                    â† ì§ˆë¬¸ íŒŒíŠ¸\n",
    "â”‚   â”œâ”€â”€ raw                     â† ì§ˆë¬¸ ì›ë¬¸\n",
    "â”‚   â”‚   â”œâ”€â”€ text                : ì§ˆë¬¸ ë‚´ìš© (ë¬¸ìì—´)\n",
    "â”‚   â”‚   â””â”€â”€ wordCount           : ë‹¨ì–´ ìˆ˜ (ì •ìˆ˜)\n",
    "â”‚   â”œâ”€â”€ emotion                 : ì§ˆë¬¸ìì˜ ê°ì • íƒœê·¸ ëª©ë¡ (ë¦¬ìŠ¤íŠ¸)\n",
    "â”‚   â”‚   â””â”€â”€ [0] object\n",
    "â”‚   â”‚        â”œâ”€â”€ text           : ê°ì •ì´ ë‚˜íƒ€ë‚œ ë¬¸ì¥\n",
    "â”‚   â”‚        â”œâ”€â”€ expression     : ê°ì • ì½”ë“œ (ì˜ˆ: p-happy, n-nervous)\n",
    "â”‚   â”‚        â””â”€â”€ category       : ê°ì • ë²”ì£¼ (positive / negative / neutral)\n",
    "â”‚   â””â”€â”€ intent                  : ì§ˆë¬¸ ì˜ë„ íƒœê·¸ ëª©ë¡ (ë¦¬ìŠ¤íŠ¸)\n",
    "â”‚        â””â”€â”€ [0] object\n",
    "â”‚             â”œâ”€â”€ text          : ì˜ë„ ì¶”ì¶œ ëŒ€ìƒ ë¬¸ì¥\n",
    "â”‚             â”œâ”€â”€ expression    : ì˜ë„ ë¼ë²¨ (ì˜ˆ: c_person)\n",
    "â”‚             â””â”€â”€ category      : ì˜ë„ ë¶„ë¥˜ ì¹´í…Œê³ ë¦¬ (ì˜ˆ: background)\n",
    "â”‚\n",
    "â””â”€â”€ answer                      â† ë‹µë³€ íŒŒíŠ¸\n",
    "    â”œâ”€â”€ raw                     â† ë‹µë³€ ì›ë¬¸\n",
    "    â”‚   â”œâ”€â”€ text                : ì§€ì›ìì˜ ë‹µë³€ ë‚´ìš© (ë¬¸ìì—´)\n",
    "    â”‚   â””â”€â”€ wordCount           : ë‹¨ì–´ ìˆ˜ (ì •ìˆ˜)\n",
    "    â”œâ”€â”€ emotion                 : ë‹µë³€ ê°ì • íƒœê·¸ ëª©ë¡ (ë¦¬ìŠ¤íŠ¸)\n",
    "    â”‚   â””â”€â”€ [0] object\n",
    "    â”‚        â”œâ”€â”€ text           : ê°ì •ì´ ë‚˜íƒ€ë‚œ ë¬¸ì¥\n",
    "    â”‚        â”œâ”€â”€ expression     : ê°ì • ì½”ë“œ (ì˜ˆ: p-happy, n-sad)\n",
    "    â”‚        â””â”€â”€ category       : ê°ì • ë²”ì£¼ (positive / negative / neutral)\n",
    "    â”œâ”€â”€ intent                  : ë‹µë³€ ì˜ë„ íƒœê·¸ ëª©ë¡ (ë¦¬ìŠ¤íŠ¸)\n",
    "    â”‚   â””â”€â”€ [0] object\n",
    "    â”‚        â”œâ”€â”€ text           : ì˜ë„ ì¶”ì¶œ ëŒ€ìƒ ë¬¸ì¥\n",
    "    â”‚        â”œâ”€â”€ expression     : ì˜ë„ ë¼ë²¨ (ì˜ˆ: c_person)\n",
    "    â”‚        â””â”€â”€ category       : ì˜ë„ ë¶„ë¥˜ ì¹´í…Œê³ ë¦¬ (ì˜ˆ: background)\n",
    "    â””â”€â”€ summary                 â† ë‹µë³€ ìš”ì•½\n",
    "        â”œâ”€â”€ text                : ìš”ì•½ ë¬¸ì¥\n",
    "        â””â”€â”€ wordCount           : ìš”ì•½ ë‹¨ì–´ ìˆ˜\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c8651b",
   "metadata": {},
   "source": [
    "## ê²°ì¸¡ì¹˜ ì°¾ê¸° \n",
    "    - í›ˆë ¨ì‹œí‚¬ ìˆ˜ ìˆëŠ” ë°ì´í„°ì…‹ í™•ì¸ : 13000ê°œ ê°€ëŸ‰ì˜ emotionë°ì´í„°ê°€ ì±„ì›Œì ¸ìˆìŒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b70583f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json\n",
    "from collections import defaultdict\n",
    "\n",
    "training_path = \"G:/ë‚´ ë“œë¼ì´ë¸Œ/ë©´ì ‘VR AIì œì‘/extracted_TrainingData\"\n",
    "valid_path = \"G:/ë‚´ ë“œë¼ì´ë¸Œ/ë©´ì ‘VR AIì œì‘/extracted_Valid\"\n",
    "\n",
    "# questionì˜ emotionì´ ë¹„ì–´ìˆê±°ë‚˜\n",
    "# answerì˜ emotionì´ ë¹„ì–´ìˆê±°ë‚˜\n",
    "def emotion_empty(base_path) : \n",
    "    emotion_count = 0\n",
    "    emotion_empty_count = 0\n",
    "    # trainingDataì˜ í´ë”ë“¤ì„ ì½ëŠ”ë‹¤.\n",
    "    for folder_name in os.listdir(base_path) : \n",
    "        folder_path = os.path.join(base_path, folder_name)\n",
    "        if not os.path.isdir(folder_path) :\n",
    "            continue\n",
    "        print(f\"{folder_name}ì„ ì‹œì‘í•©ë‹ˆë‹¤.\")\n",
    "        # folderë‚´ .jsoníŒŒì¼ë“¤ì„ ì½ëŠ”ë‹¤.\n",
    "        try : \n",
    "            for file_name in os.listdir(folder_path) : \n",
    "                if not file_name.endswith(\".json\") : \n",
    "                    continue\n",
    "                file_path = os.path.join(folder_path, file_name)\n",
    "                \n",
    "                with open(file_path, 'r', encoding=\"utf-8\") as f: \n",
    "                    data = json.load(f)\n",
    "                \n",
    "                for qa_type in ['question','answer'] : \n",
    "                    emotion = data.get('dataSet', {}).get(qa_type,{}).get('emotion', [])\n",
    "                    if not emotion : \n",
    "                        emotion_empty_count += 1\n",
    "                    else :\n",
    "                        emotion_count += 1\n",
    "\n",
    "        except Exception as e : \n",
    "            print(f\"{folder_name}ì´ ë¹„ì—ˆìŠµë‹ˆë‹¤\")\n",
    "        print(f\"{folder_name}ì„ ì¢…ë£Œ!.\")\n",
    "    return (emotion_empty_count, emotion_count)\n",
    "\n",
    "emotion_empty(training_path)\n",
    "emotion_empty(valid_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5735d3d",
   "metadata": {},
   "source": [
    "## emotionì´ ì–´ë–»ê²Œ ì´ë¤„ì ¸ìˆëŠ”ì§€ íŒŒì•…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30185bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_path = \"G:/ë‚´ ë“œë¼ì´ë¸Œ/ë©´ì ‘VR AIì œì‘/extracted_TrainingData\"\n",
    "valid_path = \"G:/ë‚´ ë“œë¼ì´ë¸Œ/ë©´ì ‘VR AIì œì‘/extracted_Valid\"\n",
    "\n",
    "\n",
    "def kinds_of_emotion(base_path) : \n",
    "    emotion_kinds = []\n",
    "\n",
    "    for folder_name in os.listdir(base_path) : \n",
    "        \n",
    "        folder_path = os.path.join(base_path, folder_name)\n",
    "        if not folder_path : \n",
    "            continue\n",
    "        try :\n",
    "            for file_name in os.listdir(folder_path) :\n",
    "                if not file_name.endswith(\".json\") : \n",
    "                    continue\n",
    "                file_path  = os.path.join(folder_path, file_name)\n",
    "                \n",
    "                with open(file_path, 'r', encoding = \"utf-8\") as f : \n",
    "                    data = json.load(f)\n",
    "                \n",
    "                for qa_type in ['question','answer'] : \n",
    "                    emotion = data.get(\"dataSet\", {}).get(qa_type, {}).get(\"emotion\", [])\n",
    "\n",
    "                    for e in emotion : \n",
    "                        if not isinstance(e, dict) : \n",
    "                            continue\n",
    "                        expr = e.get(\"expression\", [])\n",
    "\n",
    "                        if isinstance(expr, str) : \n",
    "                            expr = [expr]\n",
    "                        elif not isinstance(expr, list) : \n",
    "                            continue\n",
    "\n",
    "                        emotion_kinds.extend(expr)\n",
    "\n",
    "        except Exception as e : \n",
    "            print(f\"{folder_name}ì´ ë¹„ì—ˆìŠµë‹ˆë‹¤\")\n",
    "                \n",
    "    return emotion_kinds\n",
    "\n",
    "def unique_emotion() : \n",
    "    train_emotions = kinds_of_emotion(training_path)\n",
    "    valid_emotions = kinds_of_emotion(valid_path)\n",
    "\n",
    "    total_emotions = train_emotions + valid_emotions\n",
    "\n",
    "    unique_emotions = sorted(set(total_emotions))\n",
    "\n",
    "    return unique_emotions\n",
    "\n",
    "result = unique_emotion()\n",
    "print(result)\n",
    "print(len(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e80f05a",
   "metadata": {},
   "source": [
    "## emotionì˜ textë³„ expressionì—°ê²°í•˜ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4334f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSVë¡œ ì €ì¥\n",
    "import csv\n",
    "\n",
    "save_dir = \"G:/ë‚´ ë“œë¼ì´ë¸Œ/ë©´ì ‘VR AIì œì‘/Code/CSVëª¨ìŒ\"\n",
    "\n",
    "def text_per_expression(base_path, save_name = \"text_per_expression.csv\") : \n",
    "    for folder_name in os.listdir(base_path) : \n",
    "        result = []\n",
    "        folder_path = os.path.join(base_path, folder_name)\n",
    "        if not folder_path : \n",
    "            continue\n",
    "        try :\n",
    "            for file_name in os.listdir(folder_path) :\n",
    "                if not file_name.endswith(\".json\") : \n",
    "                    continue\n",
    "                file_path  = os.path.join(folder_path, file_name)\n",
    "                \n",
    "                with open(file_path, 'r', encoding = \"utf-8\") as f : \n",
    "                    data = json.load(f)\n",
    "                \n",
    "                for qa_type in ['question','answer'] : \n",
    "                    emotion = data.get(\"dataSet\", {}).get(qa_type, {}).get(\"emotion\", [])\n",
    "\n",
    "                    for e in emotion : \n",
    "                        if not isinstance(e, dict) : \n",
    "                            continue\n",
    "                        text = e.get(\"text\", \"\").strip()\n",
    "                        if not text : \n",
    "                            continue\n",
    "\n",
    "                        expr = e.get(\"expression\", [])\n",
    "\n",
    "                        if isinstance(expr, str) : \n",
    "                            expr = [expr]\n",
    "                        elif not isinstance(expr, list) : \n",
    "                            continue\n",
    "                        \n",
    "                        result.append(\"text\", \",\".join(expr))\n",
    "                        \n",
    "        except Exception as e : \n",
    "            print(f\"{folder_name}ì´ ë¹„ì—ˆìŠµë‹ˆë‹¤\")\n",
    "\n",
    "    save_path = os.path.join(save_dir, save_name) \n",
    "    with open(save_path, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\"text\", \"expressions\"])\n",
    "        writer.writerows(result)\n",
    "\n",
    "    return save_path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6447f3",
   "metadata": {},
   "source": [
    "## p- : positive, n- : negative, u- uncertainìœ¼ë¡œ ëª…ëª…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "575d5f22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>expression</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ë©€í‹° ì±„ë„ì€ ê¸°ì¡´ì— ìš°ë¦¬ê°€ ì‚¬ìš©í•˜ê³  ìˆëŠ” ì±„ë„ì„ ë§í•˜ëŠ”ë° ì–´ ì‰½ê²Œ ì´ì•¼ê¸°í•˜ë©´ í‹°ë¹„ë‚˜...</td>\n",
       "      <td>u-fact</td>\n",
       "      <td>uncertain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ë°˜ë©´ì— ì˜´ë‹ˆ ì±„ë„ì€ ì˜¨ ì˜¤í”„ë¼ì¸ ëª¨ë°”ì¼ ë“± ë‹¤ì–‘í•œ ì±„ë„ì„ í†µí•´ì„œ ìƒí’ˆì„ ê²€ìƒ‰í•˜ê³  êµ¬...</td>\n",
       "      <td>u-fact</td>\n",
       "      <td>uncertain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ì˜ˆë¥¼ ë“¤ì–´ ìŠ¤ë§ˆíŠ¸í° ê·¼ê±°ë¦¬ í†µì‹  ê¸°ìˆ ì„ ì´ìš©í•´ì„œ ë§ˆíŠ¸ ì•ì„ ì§€ë‚˜ëŠ” ê³ ê°ì—ê²Œ ì¿ í°ì„ ...</td>\n",
       "      <td>u-fact</td>\n",
       "      <td>uncertain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ë‘ ê°œì— ì°¨ì´ì ì€ ë©€í‹° ì±„ë„ì€ ìš´ì˜í•˜ê³  ìˆëŠ” ê° ì±„ë„ì„ ë…ë¦½ì ìœ¼ë¡œ ìš´ì˜í•´ì„œ ì˜¨ ì˜¤í”„...</td>\n",
       "      <td>u-fact</td>\n",
       "      <td>uncertain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ì œê°€ ì¤‘êµ­ì—ì„œ ì¼ ë…„ ì •ë„ ìœ í•™ ìƒí™œì„ í–ˆì—ˆëŠ”ë°ìš”.</td>\n",
       "      <td>u-fact</td>\n",
       "      <td>uncertain</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text expression  sentiment\n",
       "0  ë©€í‹° ì±„ë„ì€ ê¸°ì¡´ì— ìš°ë¦¬ê°€ ì‚¬ìš©í•˜ê³  ìˆëŠ” ì±„ë„ì„ ë§í•˜ëŠ”ë° ì–´ ì‰½ê²Œ ì´ì•¼ê¸°í•˜ë©´ í‹°ë¹„ë‚˜...     u-fact  uncertain\n",
       "1  ë°˜ë©´ì— ì˜´ë‹ˆ ì±„ë„ì€ ì˜¨ ì˜¤í”„ë¼ì¸ ëª¨ë°”ì¼ ë“± ë‹¤ì–‘í•œ ì±„ë„ì„ í†µí•´ì„œ ìƒí’ˆì„ ê²€ìƒ‰í•˜ê³  êµ¬...     u-fact  uncertain\n",
       "2  ì˜ˆë¥¼ ë“¤ì–´ ìŠ¤ë§ˆíŠ¸í° ê·¼ê±°ë¦¬ í†µì‹  ê¸°ìˆ ì„ ì´ìš©í•´ì„œ ë§ˆíŠ¸ ì•ì„ ì§€ë‚˜ëŠ” ê³ ê°ì—ê²Œ ì¿ í°ì„ ...     u-fact  uncertain\n",
       "3  ë‘ ê°œì— ì°¨ì´ì ì€ ë©€í‹° ì±„ë„ì€ ìš´ì˜í•˜ê³  ìˆëŠ” ê° ì±„ë„ì„ ë…ë¦½ì ìœ¼ë¡œ ìš´ì˜í•´ì„œ ì˜¨ ì˜¤í”„...     u-fact  uncertain\n",
       "4                       ì œê°€ ì¤‘êµ­ì—ì„œ ì¼ ë…„ ì •ë„ ìœ í•™ ìƒí™œì„ í–ˆì—ˆëŠ”ë°ìš”.     u-fact  uncertain"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "\n",
    "data = pd.read_csv(\"/home/j-k13b204/S13P31B204/model_test/Code/csv_collection/emotion_grouping.csv\")\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e1fb110",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['u-fact', 'p-happiness', 'p-interest', 'p-affection',\n",
       "       'p-achievement', 'n-anxiety', 'n-distress', 'u-belief',\n",
       "       'n-sadness', 'p-gratitude', 'n-anger', 'n-shame'], dtype=object)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['expression'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1738772a",
   "metadata": {},
   "source": [
    "### sentimentì— ì—…ë°ì´íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecfbd301",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"sentiment\"] = (\n",
    "    data[\"expression\"]\n",
    "      .astype(str)\n",
    "      .str.extract(r\"^([unp])-\", expand=False)\n",
    "      .map({\"u\": \"uncertain\", \"n\": \"negative\", \"p\": \"positive\"})\n",
    "      .fillna(\"unknown\")\n",
    ")\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c765d448",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# csvíŒŒì¼ ì œì‘\n",
    "data.to_csv(\"./CSVá„†á…©á„‹á…³á†·/emotion_csv/emotion_grouping.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd1b6fe6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label_encoding\n",
       "0    9488\n",
       "2    8068\n",
       "1    2231\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_map = {\"uncertain\": 0, \"negative\": 1, \"positive\": 2}\n",
    "\n",
    "data[\"label_encoding\"] = (\n",
    "    data[\"sentiment\"]\n",
    "        .map(label_map)            # ë¬¸ìì—´ â†’ ìˆ«ì ë§¤í•‘\n",
    "        .fillna(-1)                # í˜¹ì‹œ ì—†ëŠ” ê°’ì€ -1 ì²˜ë¦¬ (unknown)\n",
    "        .astype(int)\n",
    ")\n",
    "\n",
    "data['label_encoding'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5148ca03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>expression</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>label_encoding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ë©€í‹° ì±„ë„ì€ ê¸°ì¡´ì— ìš°ë¦¬ê°€ ì‚¬ìš©í•˜ê³  ìˆëŠ” ì±„ë„ì„ ë§í•˜ëŠ”ë° ì–´ ì‰½ê²Œ ì´ì•¼ê¸°í•˜ë©´ í‹°ë¹„ë‚˜...</td>\n",
       "      <td>u-fact</td>\n",
       "      <td>uncertain</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ë°˜ë©´ì— ì˜´ë‹ˆ ì±„ë„ì€ ì˜¨ ì˜¤í”„ë¼ì¸ ëª¨ë°”ì¼ ë“± ë‹¤ì–‘í•œ ì±„ë„ì„ í†µí•´ì„œ ìƒí’ˆì„ ê²€ìƒ‰í•˜ê³  êµ¬...</td>\n",
       "      <td>u-fact</td>\n",
       "      <td>uncertain</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ì˜ˆë¥¼ ë“¤ì–´ ìŠ¤ë§ˆíŠ¸í° ê·¼ê±°ë¦¬ í†µì‹  ê¸°ìˆ ì„ ì´ìš©í•´ì„œ ë§ˆíŠ¸ ì•ì„ ì§€ë‚˜ëŠ” ê³ ê°ì—ê²Œ ì¿ í°ì„ ...</td>\n",
       "      <td>u-fact</td>\n",
       "      <td>uncertain</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ë‘ ê°œì— ì°¨ì´ì ì€ ë©€í‹° ì±„ë„ì€ ìš´ì˜í•˜ê³  ìˆëŠ” ê° ì±„ë„ì„ ë…ë¦½ì ìœ¼ë¡œ ìš´ì˜í•´ì„œ ì˜¨ ì˜¤í”„...</td>\n",
       "      <td>u-fact</td>\n",
       "      <td>uncertain</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ì œê°€ ì¤‘êµ­ì—ì„œ ì¼ ë…„ ì •ë„ ìœ í•™ ìƒí™œì„ í–ˆì—ˆëŠ”ë°ìš”.</td>\n",
       "      <td>u-fact</td>\n",
       "      <td>uncertain</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text expression  sentiment  \\\n",
       "0  ë©€í‹° ì±„ë„ì€ ê¸°ì¡´ì— ìš°ë¦¬ê°€ ì‚¬ìš©í•˜ê³  ìˆëŠ” ì±„ë„ì„ ë§í•˜ëŠ”ë° ì–´ ì‰½ê²Œ ì´ì•¼ê¸°í•˜ë©´ í‹°ë¹„ë‚˜...     u-fact  uncertain   \n",
       "1  ë°˜ë©´ì— ì˜´ë‹ˆ ì±„ë„ì€ ì˜¨ ì˜¤í”„ë¼ì¸ ëª¨ë°”ì¼ ë“± ë‹¤ì–‘í•œ ì±„ë„ì„ í†µí•´ì„œ ìƒí’ˆì„ ê²€ìƒ‰í•˜ê³  êµ¬...     u-fact  uncertain   \n",
       "2  ì˜ˆë¥¼ ë“¤ì–´ ìŠ¤ë§ˆíŠ¸í° ê·¼ê±°ë¦¬ í†µì‹  ê¸°ìˆ ì„ ì´ìš©í•´ì„œ ë§ˆíŠ¸ ì•ì„ ì§€ë‚˜ëŠ” ê³ ê°ì—ê²Œ ì¿ í°ì„ ...     u-fact  uncertain   \n",
       "3  ë‘ ê°œì— ì°¨ì´ì ì€ ë©€í‹° ì±„ë„ì€ ìš´ì˜í•˜ê³  ìˆëŠ” ê° ì±„ë„ì„ ë…ë¦½ì ìœ¼ë¡œ ìš´ì˜í•´ì„œ ì˜¨ ì˜¤í”„...     u-fact  uncertain   \n",
       "4                       ì œê°€ ì¤‘êµ­ì—ì„œ ì¼ ë…„ ì •ë„ ìœ í•™ ìƒí™œì„ í–ˆì—ˆëŠ”ë°ìš”.     u-fact  uncertain   \n",
       "\n",
       "   label_encoding  \n",
       "0               0  \n",
       "1               0  \n",
       "2               0  \n",
       "3               0  \n",
       "4               0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9324df8",
   "metadata": {},
   "source": [
    "## ëª¨ë¸ ì–‘ìí™”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865aab1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ëª¨ë¸/í† í¬ë‚˜ì´ì € ë¡œë“œ ì¤‘...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ ë¡œë“œ ì™„ë£Œ\n",
      "\n",
      "================================================================================\n",
      "ğŸ­ ê°ì • ë¶„ì„ ê²°ê³¼\n",
      "================================================================================\n",
      "\n",
      "ì´ 2ê°œì˜ ë¬¸ì¥ì´ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "[ë¬¸ì¥ 1]\n",
      "ë‚´ìš©: ë©´ì ‘ì„ ì¤€ë¹„í•˜ë©´ì„œ ê¸´ì¥ê°ë„ ìˆì—ˆì§€ë§Œ, ì œ ê°•ì ì„ ì¶©ë¶„íˆ ë³´ì—¬ì¤„ ìˆ˜ ìˆì–´ì„œ ë¿Œë“¯í–ˆìŠµë‹ˆë‹¤.\n",
      "ê°ì •: label_0 (í™•ì‹ ë„: 38.62%)\n",
      "ì„¸ë¶€ í™•ë¥ :\n",
      "  - label_0: 38.62%\n",
      "  - label_1: 37.31%\n",
      "  - label_2: 24.07%\n",
      "--------------------------------------------------------------------------------\n",
      "[ë¬¸ì¥ 2]\n",
      "ë‚´ìš©: ì–´ë ¤ìš´ ì§ˆë¬¸ë„ ìˆì—ˆì§€ë§Œ ì°¨ë¶„í•˜ê²Œ ë‹µë³€í•˜ë ¤ê³  ë…¸ë ¥í–ˆê³ , ê²°ê³¼ì ìœ¼ë¡œ ë§Œì¡±ìŠ¤ëŸ¬ìš´ ê²½í—˜ì´ì—ˆìŠµë‹ˆë‹¤.\n",
      "ê°ì •: label_1 (í™•ì‹ ë„: 38.43%)\n",
      "ì„¸ë¶€ í™•ë¥ :\n",
      "  - label_0: 36.82%\n",
      "  - label_1: 38.43%\n",
      "  - label_2: 24.76%\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "================================================================================\n",
      "ğŸ“Š ê°ì • ìš”ì•½\n",
      "================================================================================\n",
      "\n",
      "ê°ì •ë³„ ë¬¸ì¥ ìˆ˜:\n",
      "  label_0: 1ê°œ (50.0%)\n",
      "  label_1: 1ê°œ (50.0%)\n",
      "\n",
      "í‰ê·  í™•ì‹ ë„: 38.52%\n"
     ]
    }
   ],
   "source": [
    "import os, re\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from kobert_transformers import get_kobert_model, get_tokenizer\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ===== 0) ê°ì • ë¼ë²¨ ê¸°ë³¸ ì´ë¦„ =====\n",
    "# ì‹¤ì œ í•™ìŠµí•œ í´ë˜ìŠ¤ ê°œìˆ˜ê°€ 3ê°œë¼ë©´ ì˜ˆì‹œ: ['positive','neutral','negative']\n",
    "# ëª¨ë¸ì— ë§ê²Œ ìë™ìœ¼ë¡œ label_0, label_1,... ìƒì„±ë¨\n",
    "def make_default_labels(num_classes: int):\n",
    "    return {i: f\"label_{i}\" for i in range(num_classes)}\n",
    "\n",
    "# ===== 1) ë¶„ë¥˜ê¸°(ì¸í¼ëŸ°ìŠ¤ ì „ìš©) =====\n",
    "class BertClassifier(nn.Module):\n",
    "    def __init__(self, bert, hidden_size=768, num_classes=3, dr_rate=0.3):\n",
    "        super().__init__()\n",
    "        self.bert = bert\n",
    "        self.dropout = nn.Dropout(dr_rate) if dr_rate and dr_rate > 0 else nn.Identity()\n",
    "        self.classifier = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask=None, token_type_ids=None):\n",
    "        outputs = self.bert(input_ids=input_ids,\n",
    "                            attention_mask=attention_mask,\n",
    "                            token_type_ids=token_type_ids)\n",
    "        pooled = outputs.pooler_output if getattr(outputs, \"pooler_output\", None) is not None else outputs[0][:, 0]\n",
    "        logits = self.classifier(self.dropout(pooled))\n",
    "        return logits\n",
    "\n",
    "\n",
    "def load_model(model_path: str, num_classes: int = 3, dr_rate: float = 0.3):\n",
    "    \"\"\"í•™ìŠµëœ ê°ì • ëª¨ë¸ ë¡œë“œ\"\"\"\n",
    "    bert = get_kobert_model()\n",
    "    model = BertClassifier(bert=bert, hidden_size=768, num_classes=num_classes, dr_rate=dr_rate)\n",
    "    state = torch.load(model_path, map_location=\"cpu\")\n",
    "\n",
    "    # ë¶ˆí•„ìš” í‚¤ ì •ë¦¬\n",
    "    for k in list(state.keys()):\n",
    "        if k.startswith(\"loss_fn\"):\n",
    "            del state[k]\n",
    "\n",
    "    model.load_state_dict(state, strict=False)\n",
    "    model.eval().to(device)\n",
    "    return model\n",
    "\n",
    "\n",
    "def split_sentences(text: str):\n",
    "    text = re.sub(r\"\\s+\", \" \", text.strip())\n",
    "    sents = re.split(r\"(?<=[.!?])\\s+\", text)\n",
    "    return [s.strip() for s in sents if s.strip()]\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_emotion(model, tokenizer, sentence: str, label_map: dict[int, str], max_len: int = 128):\n",
    "    \"\"\"ë‹¨ì¼ ë¬¸ì¥ì˜ ê°ì • ì˜ˆì¸¡\"\"\"\n",
    "    enc = tokenizer(\n",
    "        sentence,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=max_len,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "    input_ids = enc[\"input_ids\"].to(device)\n",
    "    attention_mask = enc[\"attention_mask\"].to(device)\n",
    "    token_type_ids = enc.get(\"token_type_ids\")\n",
    "    token_type_ids = token_type_ids.to(device) if token_type_ids is not None else None\n",
    "\n",
    "    logits = model(input_ids, attention_mask, token_type_ids)\n",
    "    probs = torch.softmax(logits, dim=-1)[0]\n",
    "    pred_idx = int(torch.argmax(probs).item())\n",
    "    label = label_map.get(pred_idx, f\"label_{pred_idx}\")\n",
    "    return label, float(probs[pred_idx].item()), probs.cpu().numpy()\n",
    "\n",
    "\n",
    "def analyze_paragraph(model, tokenizer, paragraph: str, label_map: dict[int, str], max_len: int = 128):\n",
    "    sents = split_sentences(paragraph)\n",
    "    print(\"=\" * 80)\n",
    "    print(\"ğŸ­ ê°ì • ë¶„ì„ ê²°ê³¼\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"\\nì´ {len(sents)}ê°œì˜ ë¬¸ì¥ì´ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤.\\n\")\n",
    "\n",
    "    results = []\n",
    "    for i, s in enumerate(sents, 1):\n",
    "        label, conf, probs = predict_emotion(model, tokenizer, s, label_map, max_len=max_len)\n",
    "        results.append({\"sentence_num\": i, \"sentence\": s, \"emotion\": label, \"confidence\": conf, \"probabilities\": probs})\n",
    "\n",
    "        print(f\"[ë¬¸ì¥ {i}]\")\n",
    "        print(f\"ë‚´ìš©: {s}\")\n",
    "        print(f\"ê°ì •: {label} (í™•ì‹ ë„: {conf:.2%})\")\n",
    "        print(\"ì„¸ë¶€ í™•ë¥ :\")\n",
    "        for idx in range(len(probs)):\n",
    "            print(f\"  - {label_map.get(idx, f'label_{idx}')}: {probs[idx]:.2%}\")\n",
    "        print(\"-\" * 80)\n",
    "    return results\n",
    "\n",
    "\n",
    "def print_summary(results):\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"ğŸ“Š ê°ì • ìš”ì•½\")\n",
    "    print(\"=\" * 80)\n",
    "    counts = {}\n",
    "    for r in results:\n",
    "        counts[r[\"emotion\"]] = counts.get(r[\"emotion\"], 0) + 1\n",
    "    print(\"\\nê°ì •ë³„ ë¬¸ì¥ ìˆ˜:\")\n",
    "    for k, v in sorted(counts.items(), key=lambda x: x[1], reverse=True):\n",
    "        print(f\"  {k}: {v}ê°œ ({v / len(results) * 100:.1f}%)\")\n",
    "    avg_conf = sum(r[\"confidence\"] for r in results) / max(1, len(results))\n",
    "    print(f\"\\ní‰ê·  í™•ì‹ ë„: {avg_conf:.2%}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # ê°ì • ëª¨ë¸ ê²½ë¡œ\n",
    "    MODEL_PATH = \"/home/j-k13b204/S13P31B204/model_test/kobert_emotion_model/model.pt\"\n",
    "    NUM_CLASSES = 3   # ì˜ˆ: ê¸ì •Â·ì¤‘ë¦½Â·ë¶€ì • (í•™ìŠµ ì‹œ í´ë˜ìŠ¤ ìˆ˜ë¡œ ë³€ê²½) 0 : \n",
    "    MAX_LEN = 128\n",
    "\n",
    "    print(\"ëª¨ë¸/í† í¬ë‚˜ì´ì € ë¡œë“œ ì¤‘...\")\n",
    "    tokenizer = get_tokenizer()\n",
    "    model = load_model(MODEL_PATH, num_classes=NUM_CLASSES, dr_rate=0.3)\n",
    "    label_map = make_default_labels(NUM_CLASSES)\n",
    "    print(\"âœ“ ë¡œë“œ ì™„ë£Œ\\n\")\n",
    "\n",
    "    paragraph = \"\"\"\n",
    "    ë©´ì ‘ì„ ì¤€ë¹„í•˜ë©´ì„œ ê¸´ì¥ê°ë„ ìˆì—ˆì§€ë§Œ, ì œ ê°•ì ì„ ì¶©ë¶„íˆ ë³´ì—¬ì¤„ ìˆ˜ ìˆì–´ì„œ ë¿Œë“¯í–ˆìŠµë‹ˆë‹¤.\n",
    "    ì–´ë ¤ìš´ ì§ˆë¬¸ë„ ìˆì—ˆì§€ë§Œ ì°¨ë¶„í•˜ê²Œ ë‹µë³€í•˜ë ¤ê³  ë…¸ë ¥í–ˆê³ , ê²°ê³¼ì ìœ¼ë¡œ ë§Œì¡±ìŠ¤ëŸ¬ìš´ ê²½í—˜ì´ì—ˆìŠµë‹ˆë‹¤.\n",
    "    \"\"\"\n",
    "\n",
    "    results = analyze_paragraph(model, tokenizer, paragraph, label_map, max_len=MAX_LEN)\n",
    "    print_summary(results)\n",
    "# label_map = {0: \"ë¶€ì •\", 1: \"ì¤‘ë¦½\", 2: \"ê¸ì •\"}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
