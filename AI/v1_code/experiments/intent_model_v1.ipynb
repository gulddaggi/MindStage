{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "00ad75c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>expression</th>\n",
       "      <th>intent_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ì•ì—ì„œë„ ë§ì”€ë“œë ¸ì§€ë§Œ ì €ëŠ” ì¤‘êµ­ì—ì„œ ì¼ ë…„ ì •ë„ ìœ í•™ ìƒí™œì„ í–ˆì—ˆìŠµë‹ˆë‹¤.</td>\n",
       "      <td>c_private</td>\n",
       "      <td>Communication</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ì•„ ë„¤ ì €ëŠ” ì œ ë‚˜ë¦„ëŒ€ë¡œ ìŠ¤íŠ¸ë ˆìŠ¤ í•´ì†Œë²•ì€ ì–´ ì²« ë²ˆì§¸ë¡œëŠ” ë“±ì‚°ì„ ì¢‹ì•„í•©ë‹ˆë‹¤.</td>\n",
       "      <td>c_private</td>\n",
       "      <td>Communication</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ì§ë¬´ ì§€ì‹ì€ ë³¸ì¸ì´ ì¡°ì§ì˜ ì¡´ì¬ê°ì„ ë‚˜íƒ€ë‚´ê³  ì—…ë¬´ ìˆ˜í–‰í•˜ëŠ” ë° ìˆì–´ì„œ ê°€ì¥ ê¸°ë³¸ì ì¸...</td>\n",
       "      <td>c_value</td>\n",
       "      <td>Communication</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ê·¸ë˜ì„œ ê²°êµ­ì€ ì§€ê¸ˆ ì „ì—­ì„ í•˜ê³  ì§€ê¸ˆ ì´ ìë¦¬ì—ì„œ ë©´ì ‘ì„ ë³´ê³  ìˆëŠ”ë° ì €ì˜ ì„ íƒì´ ...</td>\n",
       "      <td>c_sincere_co</td>\n",
       "      <td>Communication</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ì–´ ì €ëŠ” ì„±ê²©ì´ ì— ì¡°ê¸ˆ ê¸‰í•œ ë¶€ë¶„ì´ ìˆì–´ìš”.</td>\n",
       "      <td>c_person</td>\n",
       "      <td>Communication</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text    expression  \\\n",
       "0           ì•ì—ì„œë„ ë§ì”€ë“œë ¸ì§€ë§Œ ì €ëŠ” ì¤‘êµ­ì—ì„œ ì¼ ë…„ ì •ë„ ìœ í•™ ìƒí™œì„ í–ˆì—ˆìŠµë‹ˆë‹¤.     c_private   \n",
       "1        ì•„ ë„¤ ì €ëŠ” ì œ ë‚˜ë¦„ëŒ€ë¡œ ìŠ¤íŠ¸ë ˆìŠ¤ í•´ì†Œë²•ì€ ì–´ ì²« ë²ˆì§¸ë¡œëŠ” ë“±ì‚°ì„ ì¢‹ì•„í•©ë‹ˆë‹¤.     c_private   \n",
       "2  ì§ë¬´ ì§€ì‹ì€ ë³¸ì¸ì´ ì¡°ì§ì˜ ì¡´ì¬ê°ì„ ë‚˜íƒ€ë‚´ê³  ì—…ë¬´ ìˆ˜í–‰í•˜ëŠ” ë° ìˆì–´ì„œ ê°€ì¥ ê¸°ë³¸ì ì¸...       c_value   \n",
       "3  ê·¸ë˜ì„œ ê²°êµ­ì€ ì§€ê¸ˆ ì „ì—­ì„ í•˜ê³  ì§€ê¸ˆ ì´ ìë¦¬ì—ì„œ ë©´ì ‘ì„ ë³´ê³  ìˆëŠ”ë° ì €ì˜ ì„ íƒì´ ...  c_sincere_co   \n",
       "4                          ì–´ ì €ëŠ” ì„±ê²©ì´ ì— ì¡°ê¸ˆ ê¸‰í•œ ë¶€ë¶„ì´ ìˆì–´ìš”.      c_person   \n",
       "\n",
       "    intent_group  \n",
       "0  Communication  \n",
       "1  Communication  \n",
       "2  Communication  \n",
       "3  Communication  \n",
       "4  Communication  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv(\"/home/j-k13b204/S13P31B204/model_test/Code/csv_collection/intent_grouping.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8733ac54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83.98805198004557"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['text_len'] = data['text'].astype(str).apply(len)\n",
    "\n",
    "data_len = data['text_len'].mean()\n",
    "data_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "70000e16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>intent_group</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Communication</td>\n",
       "      <td>19963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Integrity</td>\n",
       "      <td>4479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Job_Competency</td>\n",
       "      <td>3777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Adaptability</td>\n",
       "      <td>2549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Teamwork_Leadership</td>\n",
       "      <td>1706</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          intent_group  count\n",
       "0        Communication  19963\n",
       "1            Integrity   4479\n",
       "2       Job_Competency   3777\n",
       "3         Adaptability   2549\n",
       "4  Teamwork_Leadership   1706"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['intent_group'].value_counts().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ab9dfa5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "502\n",
      "ì €ëŠ” ê¸°ë³¸ì ìœ¼ë¡œ ê·¸ ëŒ€ì¸ê´€ê³„ë„ ì¢€ ì¢‹ì€ í¸ì´ê³  ì–´ ì‚¬ëŒë“¤ê³¼ ì–´ë–¤ í™œë™ì„ ê°™ì´ í•˜ëŠ” ê±° ì´ëŸ° ê±° êµ‰ì¥íˆ ì¢‹ì•„í•´ì„œ   ìŒ ì†Œí†µ ëŠ¥ë ¥ì´ ì¢€ ë›°ì–´ë‚œ í¸ì´ë¼ê³  ìƒê°ì„ í•˜ëŠ”ë° ì•„ ì´ ì§€ê¸ˆ ì œê°€ ê°€ì§„ ê²ƒë³´ë‹¤ ë” ë§ì€ ì†Œí†µ ëŠ¥ë ¥ì„ í‚¤ìš°ê³    ê·¸ê²ƒì„ ê¸°ë°˜ìœ¼ë¡œ í•´ì„œ ì–´ë–¤ ëŠ¥ë ¥ì„ ë°œíœ˜ë¥¼ í•´ì•¼ í•œë‹¤ë©´ ì €ëŠ” ë‹¤ì–‘í•œ ëª¨ì„ì„ ë‚˜ê°€ì„œ ì—¬ëŸ¬ ê°€ì§€ ìƒí™©ê³¼ ì—¬ëŸ¬ ê°€ì§€ ì´ì•¼ê¸° ê·¸ë¦¬ê³  ë‹¤ì–‘ì„±ì„ ê°€ì§„ ì‚¬ëŒë“¤ê³¼   ìŒ ì ‘í•˜ê³  ì–´ë–¤ í™œë™ì„ í•˜ë©´ì„œ ìì—°ìŠ¤ëŸ½ê²Œ ê·¸ ì†Œí†µì„ í•  ìˆ˜ ìˆëŠ” ë…¸í•˜ìš°ë‚˜   ê·¸ëŸ° ëŠ¥ë ¥ì„ ì¢€ í•¨ì–‘ì„ í•  ìˆ˜ ìˆì—ˆìœ¼ë©´ í•˜êµ¬ìš”. ê·¸ ì™¸ì— ê·¸ ì–´ë–¤ ì£¼ì œë¥¼ ë†“ê³    ì•„ ë§ì€ ì´ì•¼ê¸°ë¥¼ ìê¸° ì˜ê²¬ì„ ì ê·¹ì ìœ¼ë¡œ ê°œì§„í•˜ë©´ì„œ ë§ì€ ì´ì•¼ê¸°ë¥¼ ë‚˜ëˆ ë³´ëŠ” ê·¸ëŸ° ì£¼ì œ ë§ì¶¤í˜• ëŒ€í™” í”„ë¡œê·¸ë¨ ê°™ì€ ê²ƒë„ ì†Œí†µ ëŠ¥ë ¥ì„ í‚¤ìš¸ ìˆ˜   ìˆëŠ” ë°©ë²•ì´ë¼ê³  ìƒê°í•´ì„œ ê·¸ëŸ° ê²ƒë„ í•´ë³´ê³  ì‹¶ë‹¤ëŠ” ìƒê°ì´ ë“¤êµ¬ìš”. ì–´ ì†Œí†µì—ì„œ ê°€ì¥ ì¤‘ìš”í•œ ê±´ ë‚´ê°€ ì–´ë–¤ ì˜ê²¬ì„   ì˜ í‘œí˜„í•˜ëŠ” ê²ƒë„ ì¤‘ìš”í•˜ì§€ë§Œ ìƒëŒ€ë°©ì˜ ê·¸ ë§ì„ ì •í™•í•˜ê²Œ ì´í•´í•˜ê³  ë°›ì•„ë“¤ì´ëŠ” ìì„¸ë„ ë„ˆë¬´ ì¤‘ìš”í•˜ê¸° ë•Œë¬¸ì—\n"
     ]
    }
   ],
   "source": [
    "# text ìµœëŒ€ê¸¸ì´ í™•ì¸\n",
    "\n",
    "max_len = 0\n",
    "max_text = \"\"\n",
    "\n",
    "for text in data['text'] : \n",
    "    length = len(str(text))\n",
    "\n",
    "    if length > max_len : \n",
    "        max_len = length\n",
    "        max_text = text\n",
    "\n",
    "\n",
    "print(max_len)\n",
    "print(max_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "efa5518d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Communication', 'Teamwork_Leadership', 'Integrity',\n",
       "       'Adaptability', 'Job_Competency'], dtype=object)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['intent_group'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73126434",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_dict = {\n",
    "    'Communication': 0,\n",
    "    'Teamwork_Leadership': 1,\n",
    "    'Integrity': 2,\n",
    "    'Adaptability': 3,\n",
    "    'Job_Competency': 4\n",
    "}\n",
    "\n",
    "data['label'] = data['intent_group'].map(label_dict)\n",
    "\n",
    "data['label'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07867dae",
   "metadata": {},
   "source": [
    "## ëª¨ë¸ ì œì‘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a5b7c786",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import AdamW    \n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from transformers import get_cosine_schedule_with_warmup \n",
    "\n",
    "from kobert_transformers import get_kobert_model, get_tokenizer\n",
    "\n",
    "# BERT ëª¨ë¸/í† í¬ë‚˜ì´ì €\n",
    "bertmodel = get_kobert_model()\n",
    "tokenizer = get_tokenizer()\n",
    "\n",
    "device = torch.device(\"cuda\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b1b63804",
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•˜ì´í¼íŒŒë¼ë¯¸í„°\n",
    "NUM_LABELS   = 5   # Communication, Integrity, Job_Competency, Adaptability, Teamwork_Leadership\n",
    "MAX_LEN      = 502\n",
    "BATCH_SIZE   = 32\n",
    "EPOCHS       = 10\n",
    "LR           = 3e-5\n",
    "WEIGHT_DECAY = 0.01\n",
    "DROPOUT      = 0.3\n",
    "PATIENCE     = 2  # validationì´ 2epochë™ì•ˆ ì¦ê°€ ì•ˆ í• ì‹œ ë©ˆì¶°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "90713473",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m----------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                   Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      6\u001b[39m     torch.backends.cudnn.deterministic = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m      7\u001b[39m     torch.backends.cudnn.benchmark = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[43mset_seed\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m42\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# MAX_LEN ì•ˆì „ì„ \u001b[39;00m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m MAX_LEN <= \u001b[32m512\u001b[39m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 5\u001b[39m, in \u001b[36mset_seed\u001b[39m\u001b[34m(seed)\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mset_seed\u001b[39m(seed=\u001b[32m42\u001b[39m):\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m     random.seed(seed); np.random.seed(seed); \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmanual_seed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m; torch.cuda.manual_seed_all(seed)\n\u001b[32m      6\u001b[39m     torch.backends.cudnn.deterministic = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m      7\u001b[39m     torch.backends.cudnn.benchmark = \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py:451\u001b[39m, in \u001b[36m_TorchDynamoContext.__call__.<locals>._fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    449\u001b[39m prior = set_eval_frame(callback)\n\u001b[32m    450\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m451\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    452\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    453\u001b[39m     set_eval_frame(prior)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/torch/_dynamo/external_utils.py:36\u001b[39m, in \u001b[36mwrap_inline.<locals>.inner\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     34\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(fn)\n\u001b[32m     35\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minner\u001b[39m(*args, **kwargs):\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/torch/random.py:45\u001b[39m, in \u001b[36mmanual_seed\u001b[39m\u001b[34m(seed)\u001b[39m\n\u001b[32m     42\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcuda\u001b[39;00m\n\u001b[32m     44\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch.cuda._is_in_bad_fork():\n\u001b[32m---> \u001b[39m\u001b[32m45\u001b[39m     \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcuda\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmanual_seed_all\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     47\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmps\u001b[39;00m\n\u001b[32m     48\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch.mps._is_in_bad_fork():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/torch/cuda/random.py:126\u001b[39m, in \u001b[36mmanual_seed_all\u001b[39m\u001b[34m(seed)\u001b[39m\n\u001b[32m    123\u001b[39m         default_generator = torch.cuda.default_generators[i]\n\u001b[32m    124\u001b[39m         default_generator.manual_seed(seed)\n\u001b[32m--> \u001b[39m\u001b[32m126\u001b[39m \u001b[43m_lazy_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed_all\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/torch/cuda/__init__.py:223\u001b[39m, in \u001b[36m_lazy_call\u001b[39m\u001b[34m(callable, **kwargs)\u001b[39m\n\u001b[32m    221\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_lazy_call\u001b[39m(\u001b[38;5;28mcallable\u001b[39m, **kwargs):\n\u001b[32m    222\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_initialized():\n\u001b[32m--> \u001b[39m\u001b[32m223\u001b[39m         \u001b[38;5;28;43mcallable\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    224\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    225\u001b[39m         \u001b[38;5;66;03m# TODO(torch_deploy): this accesses linecache, which attempts to read the\u001b[39;00m\n\u001b[32m    226\u001b[39m         \u001b[38;5;66;03m# file system to get traceback info. Patch linecache or do something\u001b[39;00m\n\u001b[32m    227\u001b[39m         \u001b[38;5;66;03m# else here if this ends up being important.\u001b[39;00m\n\u001b[32m    228\u001b[39m         \u001b[38;5;28;01mglobal\u001b[39;00m _lazy_seed_tracker\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/torch/cuda/random.py:124\u001b[39m, in \u001b[36mmanual_seed_all.<locals>.cb\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    122\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(device_count()):\n\u001b[32m    123\u001b[39m     default_generator = torch.cuda.default_generators[i]\n\u001b[32m--> \u001b[39m\u001b[32m124\u001b[39m     \u001b[43mdefault_generator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmanual_seed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "import os, random\n",
    "import numpy as np\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed); np.random.seed(seed); torch.manual_seed(seed); torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    \n",
    "set_seed(42)\n",
    "\n",
    "# MAX_LEN ì•ˆì „ì„ \n",
    "assert MAX_LEN <= 512\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff2b7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset class êµ¬ì„±\n",
    "\n",
    "class BertClassifier(nn.Module) : \n",
    "    def __init__(self, \n",
    "                 bert,\n",
    "                 hidden_size : int = 768,\n",
    "                 num_classes : int = 5,\n",
    "                 dr_rate : float = 0.3,\n",
    "                 class_weights: torch.Tensor | None = None) :\n",
    "        super().__init__()\n",
    "        self.bert = bert\n",
    "        self.dropout = nn.Dropout(p=dr_rate) if dr_rate and dr_rate > 0 else nn.Identity()\n",
    "        self.classifier = nn.Linear(hidden_size, num_classes)\n",
    "        self.loss_fn = nn.CrossEntropyLoss(weight=class_weights) if class_weights is not None else nn.CrossEntropyLoss()\n",
    "    \n",
    "    def forward(self,\n",
    "                input_ids: torch.Tensor, # ë¬¸ì¥ì„ ìˆ«ìë¡œ ë°”ê¾¼ ê²°ê³¼\n",
    "                attention_mask: torch.Tensor | None = None, # ì‹¤ì œ ë‹¨ì–´ì™€ padë¥¼ êµ¬ë¶„\n",
    "                token_type_ids: torch.Tensor | None = None, # ì„¸ê·¸ë¨¼íŠ¸ ì •ë³´\n",
    "                labels: torch.Tensor | None = None):\n",
    "        \n",
    "        outputs = self.bert(input_ids = input_ids,\n",
    "                            attention_mask = attention_mask,\n",
    "                            token_type_ids = token_type_ids)\n",
    "        \n",
    "        # HF ì¶œë ¥ í˜¸í™˜: pooler ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ [CLS]\n",
    "        if hasattr(outputs, \"pooler_output\") and outputs.pooler_output is not None:\n",
    "            pooled = outputs.pooler_output                       # (B, 768)\n",
    "        else:\n",
    "            pooled = outputs[0][:, 0]                            # last_hidden_state[:, 0]\n",
    "\n",
    "        logits = self.classifier(self.dropout(pooled))           # (B, num_classes)\n",
    "\n",
    "        if labels is not None:\n",
    "            loss = self.loss_fn(logits, labels)\n",
    "            return logits, loss\n",
    "        return logits, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fa04943f",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "['label']",
     "output_type": "error",
     "traceback": [
      "\u001b[31m----------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[32m/tmp/ipykernel_4188375/3565350374.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m sklearn.model_selection \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[32m      2\u001b[39m \n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m train_df, valid_df = train_test_split(data.dropna(subset =['text','label']),\n\u001b[32m      4\u001b[39m     test_size=\u001b[32m0.3\u001b[39m, random_state=\u001b[32m42\u001b[39m, stratify=data[\u001b[33m'label'\u001b[39m]\n\u001b[32m      5\u001b[39m )\n\u001b[32m      6\u001b[39m \n",
      "\u001b[32m~/.local/lib/python3.12/site-packages/pandas/core/frame.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, axis, how, thresh, subset, inplace, ignore_index)\u001b[39m\n\u001b[32m   6688\u001b[39m             ax = self._get_axis(agg_axis)\n\u001b[32m   6689\u001b[39m             indices = ax.get_indexer_for(subset)\n\u001b[32m   6690\u001b[39m             check = indices == -\u001b[32m1\u001b[39m\n\u001b[32m   6691\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m check.any():\n\u001b[32m-> \u001b[39m\u001b[32m6692\u001b[39m                 \u001b[38;5;28;01mraise\u001b[39;00m KeyError(np.array(subset)[check].tolist())\n\u001b[32m   6693\u001b[39m             agg_obj = self.take(indices, axis=agg_axis)\n\u001b[32m   6694\u001b[39m \n\u001b[32m   6695\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m thresh \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m lib.no_default:\n",
      "\u001b[31mKeyError\u001b[39m: ['label']"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, valid_df = train_test_split(data.dropna(subset =['text','label']),\n",
    "    test_size=0.3, random_state=42, stratify=data['label']                                      \n",
    ")\n",
    "\n",
    "import numpy as np\n",
    "counts = train_df[\"label\"].value_counts().sort_index()\n",
    "N, K = counts.sum(), counts.shape[0]\n",
    "class_weights = torch.tensor([float(N/(counts[i]*K)) for i in range(K)], dtype=torch.float32).to(device)\n",
    "print(\"class_weights:\", class_weights)\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd31fa6-414f-4d3a-b562-2784c950e4a6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m----------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                      Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 35\u001b[39m\n\u001b[32m     32\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m item\n\u001b[32m     34\u001b[39m \u001b[38;5;66;03m# ë¯¸ë‹ˆë°°ì¹˜ ë‹¨ìœ„ë¡œ í…ì„œ ë¬¶ìŒ\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m train_loader = DataLoader(IntentDataset(\u001b[43mtrain_df\u001b[49m, tokenizer, MAX_LEN), batch_size=BATCH_SIZE, shuffle=\u001b[38;5;28;01mTrue\u001b[39;00m,  num_workers=\u001b[32m2\u001b[39m, pin_memory=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     36\u001b[39m valid_loader = DataLoader(IntentDataset(valid_df, tokenizer, MAX_LEN), batch_size=BATCH_SIZE, shuffle=\u001b[38;5;28;01mFalse\u001b[39;00m, num_workers=\u001b[32m2\u001b[39m, pin_memory=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[31mNameError\u001b[39m: name 'train_df' is not defined"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# í•œ ë¬¸ì¥ì”© KoBertí† í¬ë‚˜ì´ì¦ˆ\n",
    "class IntentDataset(Dataset) : \n",
    "    def __init__(self, data, tokenizer, max_len) : \n",
    "        self.texts = data['text'].astype(str).tolist()\n",
    "        self.labels = data['label'].astype(int).tolist()\n",
    "        self.tok = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self) : return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx) :\n",
    "        enc = self.tok(\n",
    "            self.texts[idx],\n",
    "            padding = 'max_length',\n",
    "            truncation = True,\n",
    "            max_length = self.max_len,\n",
    "            return_tensors = 'pt'\n",
    "        )\n",
    "\n",
    "        item = {\n",
    "            \"input_ids\" : enc[\"input_ids\"].squeeze(0),\n",
    "            \"attention_mask\" : enc[\"attention_mask\"].squeeze(0),\n",
    "            \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        }\n",
    "\n",
    "        if \"token_type_ids\" in enc : \n",
    "            item[\"token_type_ids\"] = enc[\"token_type_ids\"].squeeze(0)\n",
    "        else : \n",
    "            item['token_type_ids'] = None\n",
    "        return item\n",
    "\n",
    "# ë¯¸ë‹ˆë°°ì¹˜ ë‹¨ìœ„ë¡œ í…ì„œ ë¬¶ìŒ\n",
    "train_loader = DataLoader(IntentDataset(train_df, tokenizer, MAX_LEN), batch_size=BATCH_SIZE, shuffle=True,  num_workers=2, pin_memory=True)\n",
    "valid_loader = DataLoader(IntentDataset(valid_df, tokenizer, MAX_LEN), batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bd60b3d2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'BertClassifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m----------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                      Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01moptim\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AdamW\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_cosine_schedule_with_warmup\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m model = \u001b[43mBertClassifier\u001b[49m(\n\u001b[32m      7\u001b[39m     bert = bertmodel,\n\u001b[32m      8\u001b[39m     hidden_size=\u001b[32m768\u001b[39m,\n\u001b[32m      9\u001b[39m     num_classes = NUM_LABELS,\n\u001b[32m     10\u001b[39m     dr_rate=DROPOUT,\n\u001b[32m     11\u001b[39m     class_weights=class_weights\n\u001b[32m     12\u001b[39m ).to(device)\n\u001b[32m     14\u001b[39m optimizer = AdamW(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n\u001b[32m     16\u001b[39m total_steps = \u001b[38;5;28mlen\u001b[39m(train_loader) * EPOCHS\n",
      "\u001b[31mNameError\u001b[39m: name 'BertClassifier' is not defined"
     ]
    }
   ],
   "source": [
    "# ëª¨ë¸ ì˜µí‹°ë§ˆì´ì €, ìŠ¤ì¼€ì¥´ëŸ¬ ì„¸íŒ…\n",
    "\n",
    "from torch.optim import AdamW\n",
    "from transformers import get_cosine_schedule_with_warmup\n",
    "\n",
    "model = BertClassifier(\n",
    "    bert = bertmodel,\n",
    "    hidden_size=768,\n",
    "    num_classes = NUM_LABELS,\n",
    "    dr_rate=DROPOUT,\n",
    "    class_weights=class_weights\n",
    ").to(device)\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "total_steps = len(train_loader) * EPOCHS\n",
    "warmup_steps = int(total_steps * 0.06)\n",
    "scheduler = get_cosine_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=warmup_steps,\n",
    "    num_training_steps=total_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d76e5c6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== EPOCH 1/10 ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 711/711 [16:58<00:00,  1.43s/it]\n",
      "Valid: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 305/305 [01:21<00:00,  3.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] loss=0.9754 acc=0.6536 f1=0.5603\n",
      "[Valid] loss=0.5931 acc=0.7989 f1=0.7344\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "      Communication     0.9522    0.7889    0.8629      5989\n",
      "Teamwork_Leadership     0.5684    0.7871    0.6601       512\n",
      "          Integrity     0.8406    0.8318    0.8362      1344\n",
      "       Adaptability     0.4963    0.7948    0.6111       765\n",
      "     Job_Competency     0.6131    0.8208    0.7019      1133\n",
      "\n",
      "           accuracy                         0.7989      9743\n",
      "          macro avg     0.6941    0.8047    0.7344      9743\n",
      "       weighted avg     0.8414    0.7989    0.8101      9743\n",
      "\n",
      ">>> Best saved. macroF1=0.7344\n",
      "\n",
      "==== EPOCH 2/10 ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 711/711 [15:01<00:00,  1.27s/it]\n",
      "Valid: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 305/305 [02:28<00:00,  2.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] loss=0.5071 acc=0.8389 f1=0.7790\n",
      "[Valid] loss=0.5759 acc=0.8246 f1=0.7626\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "      Communication     0.9518    0.8243    0.8835      5989\n",
      "Teamwork_Leadership     0.7173    0.7188    0.7180       512\n",
      "          Integrity     0.7368    0.8936    0.8077      1344\n",
      "       Adaptability     0.5417    0.7974    0.6452       765\n",
      "     Job_Competency     0.7133    0.8102    0.7587      1133\n",
      "\n",
      "           accuracy                         0.8246      9743\n",
      "          macro avg     0.7322    0.8089    0.7626      9743\n",
      "       weighted avg     0.8499    0.8246    0.8311      9743\n",
      "\n",
      ">>> Best saved. macroF1=0.7626\n",
      "\n",
      "==== EPOCH 3/10 ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 711/711 [19:32<00:00,  1.65s/it]\n",
      "Valid: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 305/305 [02:27<00:00,  2.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] loss=0.3383 acc=0.8866 f1=0.8482\n",
      "[Valid] loss=0.6083 acc=0.8332 f1=0.7728\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "      Communication     0.9482    0.8347    0.8878      5989\n",
      "Teamwork_Leadership     0.5610    0.8535    0.6770       512\n",
      "          Integrity     0.7959    0.8705    0.8316      1344\n",
      "       Adaptability     0.7490    0.7176    0.7330       765\n",
      "     Job_Competency     0.6467    0.8500    0.7346      1133\n",
      "\n",
      "           accuracy                         0.8332      9743\n",
      "          macro avg     0.7402    0.8253    0.7728      9743\n",
      "       weighted avg     0.8562    0.8332    0.8390      9743\n",
      "\n",
      ">>> Best saved. macroF1=0.7728\n",
      "\n",
      "==== EPOCH 4/10 ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 711/711 [19:23<00:00,  1.64s/it]\n",
      "Valid: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 305/305 [02:27<00:00,  2.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] loss=0.2352 acc=0.9200 f1=0.8946\n",
      "[Valid] loss=0.6871 acc=0.8566 f1=0.7919\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "      Communication     0.9335    0.8840    0.9081      5989\n",
      "Teamwork_Leadership     0.6071    0.8301    0.7013       512\n",
      "          Integrity     0.8128    0.8757    0.8431      1344\n",
      "       Adaptability     0.7799    0.6902    0.7323       765\n",
      "     Job_Competency     0.7394    0.8138    0.7748      1133\n",
      "\n",
      "           accuracy                         0.8566      9743\n",
      "          macro avg     0.7746    0.8187    0.7919      9743\n",
      "       weighted avg     0.8651    0.8566    0.8589      9743\n",
      "\n",
      ">>> Best saved. macroF1=0.7919\n",
      "\n",
      "==== EPOCH 5/10 ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 711/711 [19:19<00:00,  1.63s/it]\n",
      "Valid: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 305/305 [02:16<00:00,  2.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] loss=0.1423 acc=0.9502 f1=0.9374\n",
      "[Valid] loss=0.8217 acc=0.8692 f1=0.8058\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "      Communication     0.9079    0.9249    0.9163      5989\n",
      "Teamwork_Leadership     0.6836    0.8145    0.7433       512\n",
      "          Integrity     0.8634    0.8512    0.8572      1344\n",
      "       Adaptability     0.7569    0.7163    0.7361       765\n",
      "     Job_Competency     0.8352    0.7246    0.7760      1133\n",
      "\n",
      "           accuracy                         0.8692      9743\n",
      "          macro avg     0.8094    0.8063    0.8058      9743\n",
      "       weighted avg     0.8697    0.8692    0.8686      9743\n",
      "\n",
      ">>> Best saved. macroF1=0.8058\n",
      "\n",
      "==== EPOCH 6/10 ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 711/711 [11:43<00:00,  1.01it/s]\n",
      "Valid: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 305/305 [02:27<00:00,  2.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] loss=0.0829 acc=0.9740 f1=0.9669\n",
      "[Valid] loss=0.9954 acc=0.8697 f1=0.8072\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "      Communication     0.9106    0.9232    0.9168      5989\n",
      "Teamwork_Leadership     0.7337    0.7695    0.7512       512\n",
      "          Integrity     0.8302    0.8661    0.8478      1344\n",
      "       Adaptability     0.8095    0.6889    0.7444       765\n",
      "     Job_Competency     0.7946    0.7582    0.7760      1133\n",
      "\n",
      "           accuracy                         0.8697      9743\n",
      "          macro avg     0.8157    0.8012    0.8072      9743\n",
      "       weighted avg     0.8688    0.8697    0.8687      9743\n",
      "\n",
      ">>> Best saved. macroF1=0.8072\n",
      "\n",
      "==== EPOCH 7/10 ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 711/711 [19:26<00:00,  1.64s/it]\n",
      "Valid: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 305/305 [02:27<00:00,  2.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] loss=0.0454 acc=0.9865 f1=0.9824\n",
      "[Valid] loss=1.1548 acc=0.8706 f1=0.8079\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "      Communication     0.9076    0.9269    0.9171      5989\n",
      "Teamwork_Leadership     0.7573    0.7559    0.7566       512\n",
      "          Integrity     0.8430    0.8668    0.8547      1344\n",
      "       Adaptability     0.7716    0.7020    0.7351       765\n",
      "     Job_Competency     0.8112    0.7432    0.7757      1133\n",
      "\n",
      "           accuracy                         0.8706      9743\n",
      "          macro avg     0.8181    0.7989    0.8079      9743\n",
      "       weighted avg     0.8689    0.8706    0.8694      9743\n",
      "\n",
      ">>> Best saved. macroF1=0.8079\n",
      "\n",
      "==== EPOCH 8/10 ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 711/711 [19:22<00:00,  1.64s/it]\n",
      "Valid: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 305/305 [02:27<00:00,  2.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] loss=0.0251 acc=0.9921 f1=0.9897\n",
      "[Valid] loss=1.2161 acc=0.8720 f1=0.8090\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "      Communication     0.9034    0.9320    0.9175      5989\n",
      "Teamwork_Leadership     0.7490    0.7520    0.7505       512\n",
      "          Integrity     0.8668    0.8571    0.8620      1344\n",
      "       Adaptability     0.7828    0.7020    0.7402       765\n",
      "     Job_Competency     0.8116    0.7414    0.7749      1133\n",
      "\n",
      "           accuracy                         0.8720      9743\n",
      "          macro avg     0.8227    0.7969    0.8090      9743\n",
      "       weighted avg     0.8701    0.8720    0.8705      9743\n",
      "\n",
      ">>> Best saved. macroF1=0.8090\n",
      "\n",
      "==== EPOCH 9/10 ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 711/711 [19:18<00:00,  1.63s/it]\n",
      "Valid: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 305/305 [02:26<00:00,  2.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] loss=0.0148 acc=0.9949 f1=0.9934\n",
      "[Valid] loss=1.2377 acc=0.8726 f1=0.8109\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "      Communication     0.9039    0.9324    0.9179      5989\n",
      "Teamwork_Leadership     0.7609    0.7520    0.7564       512\n",
      "          Integrity     0.8791    0.8385    0.8583      1344\n",
      "       Adaptability     0.7679    0.7137    0.7398       765\n",
      "     Job_Competency     0.8068    0.7590    0.7822      1133\n",
      "\n",
      "           accuracy                         0.8726      9743\n",
      "          macro avg     0.8237    0.7991    0.8109      9743\n",
      "       weighted avg     0.8710    0.8726    0.8714      9743\n",
      "\n",
      ">>> Best saved. macroF1=0.8109\n",
      "\n",
      "==== EPOCH 10/10 ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 711/711 [13:58<00:00,  1.18s/it]\n",
      "Valid: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 305/305 [01:21<00:00,  3.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] loss=0.0110 acc=0.9964 f1=0.9953\n",
      "[Valid] loss=1.2492 acc=0.8727 f1=0.8107\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "      Communication     0.9052    0.9312    0.9180      5989\n",
      "Teamwork_Leadership     0.7644    0.7539    0.7591       512\n",
      "          Integrity     0.8702    0.8527    0.8613      1344\n",
      "       Adaptability     0.7773    0.6980    0.7355       765\n",
      "     Job_Competency     0.8015    0.7590    0.7797      1133\n",
      "\n",
      "           accuracy                         0.8727      9743\n",
      "          macro avg     0.8237    0.7990    0.8107      9743\n",
      "       weighted avg     0.8709    0.8727    0.8714      9743\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# í•™ìŠµ/ê²€ì¦ ë£¨í”„\n",
    "\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "\n",
    "def train_one_epoch(model, loader):\n",
    "    model.train()\n",
    "    total_loss, all_p, all_y = 0.0, [], []\n",
    "    for batch in tqdm(loader, desc=\"Train\"):\n",
    "        input_ids      = batch[\"input_ids\"].to(device, non_blocking=True)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device, non_blocking=True)\n",
    "        token_type_ids = batch[\"token_type_ids\"]\n",
    "        if token_type_ids is not None:\n",
    "            token_type_ids = token_type_ids.to(device, non_blocking=True)\n",
    "        labels         = batch[\"labels\"].to(device, non_blocking=True)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logits, loss = model(input_ids, attention_mask, token_type_ids, labels)\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        all_p.extend(torch.argmax(logits, 1).detach().cpu().tolist())\n",
    "        all_y.extend(labels.detach().cpu().tolist())\n",
    "    return total_loss/len(loader), accuracy_score(all_y, all_p), f1_score(all_y, all_p, average=\"macro\")\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, loader, target_names=None):\n",
    "    model.eval()\n",
    "    total_loss, all_p, all_y = 0.0, [], []\n",
    "    for batch in tqdm(loader, desc=\"Valid\"):\n",
    "        input_ids      = batch[\"input_ids\"].to(device, non_blocking=True)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device, non_blocking=True)\n",
    "        token_type_ids = batch[\"token_type_ids\"]\n",
    "        if token_type_ids is not None:\n",
    "            token_type_ids = token_type_ids.to(device, non_blocking=True)\n",
    "        labels         = batch[\"labels\"].to(device, non_blocking=True)\n",
    "\n",
    "        logits, loss = model(input_ids, attention_mask, token_type_ids, labels)\n",
    "        if loss is not None:\n",
    "            total_loss += loss.item()\n",
    "        all_p.extend(torch.argmax(logits, 1).detach().cpu().tolist())\n",
    "        all_y.extend(labels.detach().cpu().tolist())\n",
    "    rep = classification_report(all_y, all_p, target_names=target_names, digits=4)\n",
    "    return total_loss/len(loader), accuracy_score(all_y, all_p), f1_score(all_y, all_p, average=\"macro\"), rep\n",
    "\n",
    "best_f1, patience = 0.0, 0\n",
    "label_dict = { 'Communication':0, 'Teamwork_Leadership':1, 'Integrity':2, 'Adaptability':3, 'Job_Competency':4 }\n",
    "label_names = [k for k,_ in sorted(label_dict.items(), key=lambda x: x[1])]\n",
    "\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    print(f\"\\n==== EPOCH {epoch}/{EPOCHS} ====\")\n",
    "    tr_loss, tr_acc, tr_f1 = train_one_epoch(model, train_loader)\n",
    "    val_loss, val_acc, val_f1, val_rep = evaluate(model, valid_loader, target_names=label_names)\n",
    "\n",
    "    print(f\"[Train] loss={tr_loss:.4f} acc={tr_acc:.4f} f1={tr_f1:.4f}\")\n",
    "    print(f\"[Valid] loss={val_loss:.4f} acc={val_acc:.4f} f1={val_f1:.4f}\")\n",
    "    print(val_rep)\n",
    "\n",
    "    if val_f1 > best_f1:\n",
    "        best_f1, patience = val_f1, 0\n",
    "        os.makedirs(\"./kobert_intent_model\", exist_ok=True)\n",
    "        torch.save(model.state_dict(), \"./kobert_intent_model/model.pt\")\n",
    "        with open(\"./kobert_intent_model/label_map.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "            for k,v in sorted(label_dict.items(), key=lambda x: x[1]):\n",
    "                f.write(f\"{v}\\t{k}\\n\")\n",
    "        print(f\">>> Best saved. macroF1={best_f1:.4f}\")\n",
    "    else:\n",
    "        patience += 1\n",
    "        if patience >= PATIENCE:\n",
    "            print(\"Early stopping.\")\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc13521",
   "metadata": {},
   "source": [
    "## ëª¨ë¸ ì‹¤í–‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6325e3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ëª¨ë¸ì„ ë¡œë“œí•˜ëŠ” ì¤‘...\n",
      "âœ“ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!\n",
      "\n",
      "================================================================================\n",
      "ğŸ“ ë¬¸ë‹¨ ë¶„ì„ ê²°ê³¼\n",
      "================================================================================\n",
      "\n",
      "ì´ 4ê°œì˜ ë¬¸ì¥ì´ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "[ë¬¸ì¥ 1]\n",
      "ë‚´ìš©: ìµœê·¼ì—ëŠ” 'VR ê¸°ë°˜ ë©´ì ‘ AI ë¶„ì„ ì‹œìŠ¤í…œ'ì„ ì§ì ‘ êµ¬í˜„í•˜ë©° ë°ì´í„° ìˆ˜ì§‘ë¶€í„° ëª¨ë¸ í•™ìŠµê¹Œì§€ì˜ ì „ ê³¼ì •ì„ ìˆ˜í–‰í–ˆìŠµë‹ˆë‹¤.\n",
      "ë¶„ë¥˜: Job_Competency (í™•ì‹ ë„: 99.95%)\n",
      "ì„¸ë¶€ í™•ë¥ :\n",
      "  - Communication: 0.02%\n",
      "  - Teamwork_Leadership: 0.00%\n",
      "  - Integrity: 0.01%\n",
      "  - Adaptability: 0.01%\n",
      "  - Job_Competency: 99.95%\n",
      "--------------------------------------------------------------------------------\n",
      "[ë¬¸ì¥ 2]\n",
      "ë‚´ìš©: AI-Hub ë©´ì ‘ ë°ì´í„°ì…‹ì„ ê°€ê³µí•˜ê³ , KoBERT ëª¨ë¸ì„ fine-tuningí•˜ì—¬ ì§€ì›ìì˜ ë‹µë³€ì„ 5ëŒ€ NCS ì—­ëŸ‰(Communication, Integrity, Adaptability, Teamwork, Job Competency) ìœ¼ë¡œ ë¶„ë¥˜í–ˆìŠµë‹ˆë‹¤.\n",
      "ë¶„ë¥˜: Teamwork_Leadership (í™•ì‹ ë„: 98.60%)\n",
      "ì„¸ë¶€ í™•ë¥ :\n",
      "  - Communication: 0.02%\n",
      "  - Teamwork_Leadership: 98.60%\n",
      "  - Integrity: 0.94%\n",
      "  - Adaptability: 0.03%\n",
      "  - Job_Competency: 0.41%\n",
      "--------------------------------------------------------------------------------\n",
      "[ë¬¸ì¥ 3]\n",
      "ë‚´ìš©: ë˜í•œ FastAPIì™€ LangChainì„ ì´ìš©í•´ GPT APIì™€ ì—°ë™í•œ ë©´ì ‘ í”¼ë“œë°± ìë™ ìƒì„± ì‹œìŠ¤í…œì„ ê°œë°œí•˜ë©° AIê°€ ë‹¨ìˆœí•œ ë¶„ì„ ë„êµ¬ê°€ ì•„ë‹Œ ê²½í—˜ì„ ê°œì„ í•˜ëŠ” ì„œë¹„ìŠ¤ê°€ ë  ìˆ˜ ìˆìŒì„ ì‹¤ê°í–ˆìŠµë‹ˆë‹¤.\n",
      "ë¶„ë¥˜: Job_Competency (í™•ì‹ ë„: 62.25%)\n",
      "ì„¸ë¶€ í™•ë¥ :\n",
      "  - Communication: 0.19%\n",
      "  - Teamwork_Leadership: 0.08%\n",
      "  - Integrity: 0.16%\n",
      "  - Adaptability: 37.32%\n",
      "  - Job_Competency: 62.25%\n",
      "--------------------------------------------------------------------------------\n",
      "[ë¬¸ì¥ 4]\n",
      "ë‚´ìš©: ì´ ê²½í—˜ì„ í†µí•´ ë°ì´í„° ë¶„ì„ê³¼ AI ì„œë¹„ìŠ¤ ê¸°íš, ê·¸ë¦¬ê³  ì‚¬ìš©ì ê²½í—˜ì„ ì—°ê²°í•˜ëŠ” ì‹œê°ì„ í‚¤ì› ìŠµë‹ˆë‹¤.\n",
      "ë¶„ë¥˜: Communication (í™•ì‹ ë„: 96.22%)\n",
      "ì„¸ë¶€ í™•ë¥ :\n",
      "  - Communication: 96.22%\n",
      "  - Teamwork_Leadership: 0.03%\n",
      "  - Integrity: 0.16%\n",
      "  - Adaptability: 0.02%\n",
      "  - Job_Competency: 3.58%\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "================================================================================\n",
      "ğŸ“Š ë¶„ì„ ìš”ì•½\n",
      "================================================================================\n",
      "\n",
      "ì˜ë„ë³„ ë¬¸ì¥ ìˆ˜:\n",
      "  Job_Competency: 2ê°œ (50.0%)\n",
      "  Teamwork_Leadership: 1ê°œ (25.0%)\n",
      "  Communication: 1ê°œ (25.0%)\n",
      "\n",
      "í‰ê·  í™•ì‹ ë„: 89.26%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from kobert_transformers import get_kobert_model, get_tokenizer\n",
    "import re\n",
    "\n",
    "# ë””ë°”ì´ìŠ¤ ì„¤ì •\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ëª¨ë¸ í´ë˜ìŠ¤ ì •ì˜ (í•™ìŠµ ë•Œì™€ ë™ì¼)\n",
    "class BertClassifier(nn.Module):\n",
    "    def __init__(self, \n",
    "                 bert,\n",
    "                 hidden_size: int = 768,\n",
    "                 num_classes: int = 5,\n",
    "                 dr_rate: float = 0.3,\n",
    "                 class_weights: torch.Tensor | None = None):\n",
    "        super().__init__()\n",
    "        self.bert = bert\n",
    "        self.dropout = nn.Dropout(p=dr_rate) if dr_rate and dr_rate > 0 else nn.Identity()\n",
    "        self.classifier = nn.Linear(hidden_size, num_classes)\n",
    "        self.loss_fn = nn.CrossEntropyLoss(weight=class_weights) if class_weights is not None else nn.CrossEntropyLoss()\n",
    "    \n",
    "    def forward(self,\n",
    "                input_ids: torch.Tensor,\n",
    "                attention_mask: torch.Tensor | None = None,\n",
    "                token_type_ids: torch.Tensor | None = None,\n",
    "                labels: torch.Tensor | None = None):\n",
    "        \n",
    "        outputs = self.bert(input_ids=input_ids,\n",
    "                            attention_mask=attention_mask,\n",
    "                            token_type_ids=token_type_ids)\n",
    "        \n",
    "        if hasattr(outputs, \"pooler_output\") and outputs.pooler_output is not None:\n",
    "            pooled = outputs.pooler_output\n",
    "        else:\n",
    "            pooled = outputs[0][:, 0]\n",
    "\n",
    "        logits = self.classifier(self.dropout(pooled))\n",
    "\n",
    "        if labels is not None:\n",
    "            loss = self.loss_fn(logits, labels)\n",
    "            return logits, loss\n",
    "        return logits, None\n",
    "\n",
    "\n",
    "def load_model(model_path, label_map_path):\n",
    "    \"\"\"í•™ìŠµëœ ëª¨ë¸ê³¼ ë¼ë²¨ ë§¤í•‘ ë¡œë“œ\"\"\"\n",
    "    \n",
    "    # ë¼ë²¨ ë§¤í•‘ ë¡œë“œ\n",
    "    label_map = {}\n",
    "    with open(label_map_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            idx, label = line.strip().split('\\t')\n",
    "            label_map[int(idx)] = label\n",
    "    \n",
    "    # ëª¨ë¸ ì´ˆê¸°í™”\n",
    "    bertmodel = get_kobert_model()\n",
    "    model = BertClassifier(\n",
    "        bert=bertmodel,\n",
    "        hidden_size=768,\n",
    "        num_classes=5,\n",
    "        dr_rate=0.3,\n",
    "        class_weights=None\n",
    "    ).to(device)\n",
    "    \n",
    "    # í•™ìŠµëœ ê°€ì¤‘ì¹˜ ë¡œë“œ (strict=Falseë¡œ ì„¤ì •í•˜ì—¬ loss_fn.weight ë¬´ì‹œ)\n",
    "    state_dict = torch.load(model_path, map_location=device)\n",
    "    \n",
    "    # loss_fn.weight ì œê±° (ìˆëŠ” ê²½ìš°)\n",
    "    if 'loss_fn.weight' in state_dict:\n",
    "        del state_dict['loss_fn.weight']\n",
    "    \n",
    "    model.load_state_dict(state_dict, strict=False)\n",
    "    model.eval()\n",
    "    \n",
    "    return model, label_map\n",
    "\n",
    "\n",
    "def split_sentences(text):\n",
    "    \"\"\"ë¬¸ë‹¨ì„ ë¬¸ì¥ìœ¼ë¡œ ë¶„ë¦¬\"\"\"\n",
    "    # ì¤„ë°”ê¿ˆ ì œê±° ë° ê³µë°± ì •ë¦¬\n",
    "    text = re.sub(r'\\s+', ' ', text.strip())\n",
    "    \n",
    "    # ë¬¸ì¥ ë¶„ë¦¬ (ë§ˆì¹¨í‘œ, ë¬¼ìŒí‘œ, ëŠë‚Œí‘œ ê¸°ì¤€)\n",
    "    sentences = re.split(r'(?<=[.!?])\\s+', text)\n",
    "    \n",
    "    # ë¹ˆ ë¬¸ì¥ ì œê±°\n",
    "    sentences = [s.strip() for s in sentences if s.strip()]\n",
    "    \n",
    "    return sentences\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_intent(model, tokenizer, sentence, label_map, max_len=502):\n",
    "    \"\"\"ë‹¨ì¼ ë¬¸ì¥ì˜ ì˜ë„ ì˜ˆì¸¡\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # í† í¬ë‚˜ì´ì§•\n",
    "    encoding = tokenizer(\n",
    "        sentence,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        max_length=max_len,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    \n",
    "    input_ids = encoding['input_ids'].to(device)\n",
    "    attention_mask = encoding['attention_mask'].to(device)\n",
    "    token_type_ids = encoding.get('token_type_ids')\n",
    "    if token_type_ids is not None:\n",
    "        token_type_ids = token_type_ids.to(device)\n",
    "    \n",
    "    # ì˜ˆì¸¡\n",
    "    logits, _ = model(input_ids, attention_mask, token_type_ids)\n",
    "    probs = torch.softmax(logits, dim=1)\n",
    "    pred_idx = torch.argmax(probs, dim=1).item()\n",
    "    confidence = probs[0][pred_idx].item()\n",
    "    \n",
    "    return label_map[pred_idx], confidence, probs[0].cpu().numpy()\n",
    "\n",
    "\n",
    "def analyze_paragraph(model, tokenizer, paragraph, label_map):\n",
    "    \"\"\"ë¬¸ë‹¨ ì „ì²´ ë¶„ì„\"\"\"\n",
    "    sentences = split_sentences(paragraph)\n",
    "    \n",
    "    print(\"=\" * 80)\n",
    "    print(\"ğŸ“ ë¬¸ë‹¨ ë¶„ì„ ê²°ê³¼\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"\\nì´ {len(sentences)}ê°œì˜ ë¬¸ì¥ì´ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤.\\n\")\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for i, sentence in enumerate(sentences, 1):\n",
    "        intent, confidence, probs = predict_intent(model, tokenizer, sentence, label_map)\n",
    "        results.append({\n",
    "            'sentence_num': i,\n",
    "            'sentence': sentence,\n",
    "            'intent': intent,\n",
    "            'confidence': confidence,\n",
    "            'probabilities': probs\n",
    "        })\n",
    "        \n",
    "        print(f\"[ë¬¸ì¥ {i}]\")\n",
    "        print(f\"ë‚´ìš©: {sentence}\")\n",
    "        print(f\"ë¶„ë¥˜: {intent} (í™•ì‹ ë„: {confidence:.2%})\")\n",
    "        \n",
    "        # ëª¨ë“  í´ë˜ìŠ¤ë³„ í™•ë¥  ì¶œë ¥\n",
    "        print(\"ì„¸ë¶€ í™•ë¥ :\")\n",
    "        for idx, prob in enumerate(probs):\n",
    "            print(f\"  - {label_map[idx]}: {prob:.2%}\")\n",
    "        print(\"-\" * 80)\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "def print_summary(results):\n",
    "    \"\"\"ìš”ì•½ í†µê³„ ì¶œë ¥\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"ğŸ“Š ë¶„ì„ ìš”ì•½\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    intent_counts = {}\n",
    "    for result in results:\n",
    "        intent = result['intent']\n",
    "        intent_counts[intent] = intent_counts.get(intent, 0) + 1\n",
    "    \n",
    "    print(\"\\nì˜ë„ë³„ ë¬¸ì¥ ìˆ˜:\")\n",
    "    for intent, count in sorted(intent_counts.items(), key=lambda x: x[1], reverse=True):\n",
    "        percentage = (count / len(results)) * 100\n",
    "        print(f\"  {intent}: {count}ê°œ ({percentage:.1f}%)\")\n",
    "    \n",
    "    avg_confidence = sum(r['confidence'] for r in results) / len(results)\n",
    "    print(f\"\\ní‰ê·  í™•ì‹ ë„: {avg_confidence:.2%}\")\n",
    "\n",
    "\n",
    "# ë©”ì¸ ì‹¤í–‰ ì½”ë“œ\n",
    "if __name__ == \"__main__\":\n",
    "    # ëª¨ë¸ ë° í† í¬ë‚˜ì´ì € ë¡œë“œ\n",
    "    MODEL_PATH = \"/home/j-k13b204/S13P31B204/model_test/kobert_intent_model/model.pt\"\n",
    "    LABEL_MAP_PATH = \"/home/j-k13b204/S13P31B204/model_test/kobert_intent_model/label_map.txt\"\n",
    "    \n",
    "    print(\"ëª¨ë¸ì„ ë¡œë“œí•˜ëŠ” ì¤‘...\")\n",
    "    tokenizer = get_tokenizer()\n",
    "    model, label_map = load_model(MODEL_PATH, LABEL_MAP_PATH)\n",
    "    print(\"âœ“ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!\\n\")\n",
    "    \n",
    "    # ë¶„ì„í•  ë¬¸ë‹¨\n",
    "    sentence = \"\"\"\n",
    "    ìµœê·¼ì—ëŠ” 'VR ê¸°ë°˜ ë©´ì ‘ AI ë¶„ì„ ì‹œìŠ¤í…œ'ì„ ì§ì ‘ êµ¬í˜„í•˜ë©°\n",
    "    ë°ì´í„° ìˆ˜ì§‘ë¶€í„° ëª¨ë¸ í•™ìŠµê¹Œì§€ì˜ ì „ ê³¼ì •ì„ ìˆ˜í–‰í–ˆìŠµë‹ˆë‹¤.\n",
    "    AI-Hub ë©´ì ‘ ë°ì´í„°ì…‹ì„ ê°€ê³µí•˜ê³ , KoBERT ëª¨ë¸ì„ fine-tuningí•˜ì—¬\n",
    "    ì§€ì›ìì˜ ë‹µë³€ì„ 5ëŒ€ NCS ì—­ëŸ‰(Communication, Integrity, Adaptability, Teamwork, Job Competency) ìœ¼ë¡œ ë¶„ë¥˜í–ˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "    ë˜í•œ FastAPIì™€ LangChainì„ ì´ìš©í•´ GPT APIì™€ ì—°ë™í•œ ë©´ì ‘ í”¼ë“œë°± ìë™ ìƒì„± ì‹œìŠ¤í…œì„ ê°œë°œí•˜ë©°\n",
    "    AIê°€ ë‹¨ìˆœí•œ ë¶„ì„ ë„êµ¬ê°€ ì•„ë‹Œ ê²½í—˜ì„ ê°œì„ í•˜ëŠ” ì„œë¹„ìŠ¤ê°€ ë  ìˆ˜ ìˆìŒì„ ì‹¤ê°í–ˆìŠµë‹ˆë‹¤.\n",
    "    ì´ ê²½í—˜ì„ í†µí•´ ë°ì´í„° ë¶„ì„ê³¼ AI ì„œë¹„ìŠ¤ ê¸°íš, ê·¸ë¦¬ê³  ì‚¬ìš©ì ê²½í—˜ì„ ì—°ê²°í•˜ëŠ” ì‹œê°ì„ í‚¤ì› ìŠµë‹ˆë‹¤.\n",
    "    \"\"\"\n",
    "    \n",
    "    # ë¶„ì„ ì‹¤í–‰\n",
    "    results = analyze_paragraph(model, tokenizer, sentence, label_map)\n",
    "    \n",
    "    # ìš”ì•½ ì¶œë ¥\n",
    "    print_summary(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520bb300",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.quantization as quant\n",
    "from kobert_transformers import get_kobert_model\n",
    "import os\n",
    "\n",
    "# ===== ëª¨ë¸ í´ë˜ìŠ¤ ì •ì˜ (ì›ë³¸ê³¼ ë™ì¼) =====\n",
    "class BertClassifier(nn.Module):\n",
    "    def __init__(self, \n",
    "                 bert,\n",
    "                 hidden_size: int = 768,\n",
    "                 num_classes: int = 5,\n",
    "                 dr_rate: float = 0.3,\n",
    "                 class_weights: torch.Tensor | None = None):\n",
    "        super().__init__()\n",
    "        self.bert = bert\n",
    "        self.dropout = nn.Dropout(p=dr_rate) if dr_rate and dr_rate > 0 else nn.Identity()\n",
    "        self.classifier = nn.Linear(hidden_size, num_classes)\n",
    "        self.loss_fn = nn.CrossEntropyLoss(weight=class_weights) if class_weights is not None else nn.CrossEntropyLoss()\n",
    "    \n",
    "    def forward(self,\n",
    "                input_ids: torch.Tensor,\n",
    "                attention_mask: torch.Tensor | None = None,\n",
    "                token_type_ids: torch.Tensor | None = None,\n",
    "                labels: torch.Tensor | None = None):\n",
    "        \n",
    "        outputs = self.bert(input_ids=input_ids,\n",
    "                            attention_mask=attention_mask,\n",
    "                            token_type_ids=token_type_ids)\n",
    "        \n",
    "        if hasattr(outputs, \"pooler_output\") and outputs.pooler_output is not None:\n",
    "            pooled = outputs.pooler_output\n",
    "        else:\n",
    "            pooled = outputs[0][:, 0]\n",
    "\n",
    "        logits = self.classifier(self.dropout(pooled))\n",
    "\n",
    "        if labels is not None:\n",
    "            loss = self.loss_fn(logits, labels)\n",
    "            return logits, loss\n",
    "        return logits, None\n",
    "\n",
    "\n",
    "def load_model(model_path):\n",
    "    \"\"\"í•™ìŠµëœ ëª¨ë¸ ë¡œë“œ\"\"\"\n",
    "    device = torch.device('cpu')  # ì–‘ìí™”ëŠ” CPUì—ì„œ ì§„í–‰\n",
    "    \n",
    "    # ëª¨ë¸ ì´ˆê¸°í™”\n",
    "    print(\"ëª¨ë¸ êµ¬ì¡° ì´ˆê¸°í™” ì¤‘...\")\n",
    "    bertmodel = get_kobert_model()\n",
    "    model = BertClassifier(\n",
    "        bert=bertmodel,\n",
    "        hidden_size=768,\n",
    "        num_classes=5,\n",
    "        dr_rate=0.3,\n",
    "        class_weights=None\n",
    "    ).to(device)\n",
    "    \n",
    "    # í•™ìŠµëœ ê°€ì¤‘ì¹˜ ë¡œë“œ\n",
    "    print(\"ê°€ì¤‘ì¹˜ ë¡œë“œ ì¤‘...\")\n",
    "    state_dict = torch.load(model_path, map_location=device)\n",
    "    \n",
    "    # loss_fn.weight ì œê±° (ìˆëŠ” ê²½ìš°)\n",
    "    if 'loss_fn.weight' in state_dict:\n",
    "        del state_dict['loss_fn.weight']\n",
    "    \n",
    "    model.load_state_dict(state_dict, strict=False)\n",
    "    model.eval()\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def quantize_model(model):\n",
    "    \"\"\"ëª¨ë¸ ë™ì  ì–‘ìí™”\"\"\"\n",
    "    print(\"\\në™ì  ì–‘ìí™” ìˆ˜í–‰ ì¤‘...\")\n",
    "    quantized_model = quant.quantize_dynamic(\n",
    "        model,\n",
    "        {nn.Linear},  # Linear ë ˆì´ì–´ ì–‘ìí™”\n",
    "        dtype=torch.qint8\n",
    "    )\n",
    "    return quantized_model\n",
    "\n",
    "\n",
    "def export_to_onnx(model, output_path, opset_version=14):\n",
    "    \"\"\"ONNX í˜•ì‹ìœ¼ë¡œ ë³€í™˜\"\"\"\n",
    "    print(f\"\\nONNX ë³€í™˜ ì¤‘ (opset_version={opset_version})...\")\n",
    "    \n",
    "    # ë”ë¯¸ ì…ë ¥ ìƒì„±\n",
    "    batch_size = 1\n",
    "    seq_length = 128\n",
    "    \n",
    "    dummy_input = {\n",
    "        'input_ids': torch.randint(0, 8002, (batch_size, seq_length), dtype=torch.long),\n",
    "        'attention_mask': torch.ones(batch_size, seq_length, dtype=torch.long),\n",
    "        'token_type_ids': torch.zeros(batch_size, seq_length, dtype=torch.long)\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        torch.onnx.export(\n",
    "            model,\n",
    "            (dummy_input['input_ids'], \n",
    "             dummy_input['attention_mask'], \n",
    "             dummy_input['token_type_ids']),\n",
    "            output_path,\n",
    "            export_params=True,\n",
    "            opset_version=opset_version,\n",
    "            do_constant_folding=True,\n",
    "            input_names=['input_ids', 'attention_mask', 'token_type_ids'],\n",
    "            output_names=['logits'],\n",
    "            dynamic_axes={\n",
    "                'input_ids': {0: 'batch_size', 1: 'sequence'},\n",
    "                'attention_mask': {0: 'batch_size', 1: 'sequence'},\n",
    "                'token_type_ids': {0: 'batch_size', 1: 'sequence'},\n",
    "                'logits': {0: 'batch_size'}\n",
    "            }\n",
    "        )\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"ONNX ë³€í™˜ ì‹¤íŒ¨: {e}\")\n",
    "        return False\n",
    "\n",
    "\n",
    "def print_model_info(path, name):\n",
    "    \"\"\"ëª¨ë¸ ì •ë³´ ì¶œë ¥\"\"\"\n",
    "    if os.path.exists(path):\n",
    "        size_mb = os.path.getsize(path) / (1024**2)\n",
    "        print(f\"  âœ“ {name}: {size_mb:.2f} MB\")\n",
    "        return size_mb\n",
    "    else:\n",
    "        print(f\"  âœ— {name}: íŒŒì¼ ì—†ìŒ\")\n",
    "        return 0\n",
    "\n",
    "\n",
    "# ===== ë©”ì¸ ì‹¤í–‰ =====\n",
    "if __name__ == \"__main__\":\n",
    "    # ê²½ë¡œ ì„¤ì •\n",
    "    MODEL_PATH = \"/home/j-k13b204/S13P31B204/model_test/kobert_intent_model/model.pt\"\n",
    "    OUTPUT_DIR = \"/home/j-k13b204/S13P31B204/model_test/kobert_intent_model/quantize\"\n",
    "    \n",
    "    QUANTIZED_PT_PATH = os.path.join(OUTPUT_DIR, \"model_quantized.pt\")\n",
    "    QUANTIZED_ONNX_PATH = os.path.join(OUTPUT_DIR, \"model_quantized.onnx\")\n",
    "    ORIGINAL_ONNX_PATH = os.path.join(OUTPUT_DIR, \"model_original.onnx\")\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    print(\"KoBERT Intent Model ì–‘ìí™” ë° ONNX ë³€í™˜\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # 1. ì›ë³¸ ëª¨ë¸ ë¡œë“œ\n",
    "    print(\"\\n[1ë‹¨ê³„] ì›ë³¸ ëª¨ë¸ ë¡œë“œ\")\n",
    "    model = load_model(MODEL_PATH)\n",
    "    original_size = print_model_info(MODEL_PATH, \"ì›ë³¸ ëª¨ë¸\")\n",
    "    \n",
    "    # 2. ì–‘ìí™”\n",
    "    print(\"\\n[2ë‹¨ê³„] ëª¨ë¸ ì–‘ìí™”\")\n",
    "    quantized_model = quantize_model(model)\n",
    "    \n",
    "    # 3. ì–‘ìí™” ëª¨ë¸ ì €ì¥ (.pt)\n",
    "    print(f\"\\nì–‘ìí™”ëœ PyTorch ëª¨ë¸ ì €ì¥ ì¤‘...\")\n",
    "    torch.save(quantized_model, QUANTIZED_PT_PATH)\n",
    "    quantized_size = print_model_info(QUANTIZED_PT_PATH, \"ì–‘ìí™” ëª¨ë¸ (.pt)\")\n",
    "    \n",
    "    # 4. ONNX ë³€í™˜ (ì–‘ìí™” ëª¨ë¸)\n",
    "    print(\"\\n[3ë‹¨ê³„] ì–‘ìí™” ëª¨ë¸ ONNX ë³€í™˜\")\n",
    "    success = export_to_onnx(quantized_model, QUANTIZED_ONNX_PATH)\n",
    "    \n",
    "    if not success:\n",
    "        print(\"\\nâš ï¸  ì–‘ìí™” ëª¨ë¸ ONNX ë³€í™˜ ì‹¤íŒ¨. ì›ë³¸ ëª¨ë¸ë¡œ ì‹œë„í•©ë‹ˆë‹¤...\")\n",
    "        print(\"\\n[ëŒ€ì•ˆ] ì›ë³¸ ëª¨ë¸ ONNX ë³€í™˜\")\n",
    "        export_to_onnx(model, ORIGINAL_ONNX_PATH)\n",
    "        print(\"\\nğŸ’¡ ì›ë³¸ ëª¨ë¸ì„ ONNXë¡œ ë³€í™˜í–ˆìŠµë‹ˆë‹¤.\")\n",
    "        print(\"   onnxruntimeì„ ì‚¬ìš©í•˜ì—¬ ONNX ëª¨ë¸ì„ ì–‘ìí™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:\")\n",
    "        print(f\"   python -m onnxruntime.quantization.preprocess --input {ORIGINAL_ONNX_PATH} --output {QUANTIZED_ONNX_PATH}\")\n",
    "    \n",
    "    # ê²°ê³¼ ìš”ì•½\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"ğŸ“Š ê²°ê³¼ ìš”ì•½\")\n",
    "    print(\"=\"*80)\n",
    "    print(\"\\nìƒì„±ëœ íŒŒì¼:\")\n",
    "    original_size = print_model_info(MODEL_PATH, \"ì›ë³¸ ëª¨ë¸\")\n",
    "    quantized_pt_size = print_model_info(QUANTIZED_PT_PATH, \"ì–‘ìí™” ëª¨ë¸ (.pt)\")\n",
    "    \n",
    "    if os.path.exists(QUANTIZED_ONNX_PATH):\n",
    "        onnx_size = print_model_info(QUANTIZED_ONNX_PATH, \"ì–‘ìí™” ëª¨ë¸ (.onnx)\")\n",
    "        print(f\"\\nâœ… ONNX ë³€í™˜ ì„±ê³µ!\")\n",
    "    elif os.path.exists(ORIGINAL_ONNX_PATH):\n",
    "        onnx_size = print_model_info(ORIGINAL_ONNX_PATH, \"ì›ë³¸ ëª¨ë¸ (.onnx)\")\n",
    "        print(f\"\\nâš ï¸  ì›ë³¸ ONNXë§Œ ìƒì„±ë¨ (ì–‘ìí™”ëŠ” ë³„ë„ ë„êµ¬ í•„ìš”)\")\n",
    "    \n",
    "    if quantized_pt_size > 0 and original_size > 0:\n",
    "        compression_ratio = original_size / quantized_pt_size\n",
    "        size_reduction = ((original_size - quantized_pt_size) / original_size) * 100\n",
    "        print(f\"\\nì••ì¶•ë¥ : {compression_ratio:.2f}x ({size_reduction:.1f}% ê°ì†Œ)\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"âœ… ì™„ë£Œ!\")\n",
    "    print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67659ccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ğŸš€ ì–‘ìí™” KoBERT ëª¨ë¸ ì¶”ë¡  (CPU ìµœì í™”)\n",
      "================================================================================\n",
      "\n",
      "ëª¨ë¸ì„ ë¡œë“œí•˜ëŠ” ì¤‘...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸  ì–‘ìí™” ëª¨ë¸ì€ CPUì—ì„œë§Œ ì‹¤í–‰ë©ë‹ˆë‹¤.\n",
      "ğŸ’¡ GPUë¥¼ ì‚¬ìš©í•˜ë ¤ë©´ ì›ë³¸ ëª¨ë¸(model.pt)ì„ ì‚¬ìš©í•˜ì„¸ìš”.\n",
      "\n",
      "ì–‘ìí™” ëª¨ë¸ ë¡œë“œ ì¤‘...\n",
      "âœ“ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ (CPU ëª¨ë“œ)\n",
      "\n",
      "================================================================================\n",
      "ğŸ“ ë¬¸ë‹¨ ë¶„ì„ ê²°ê³¼\n",
      "================================================================================\n",
      "\n",
      "ì´ 4ê°œì˜ ë¬¸ì¥ì´ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "[ë¬¸ì¥ 1]\n",
      "ë‚´ìš©: ìµœê·¼ì—ëŠ” 'VR ê¸°ë°˜ ë©´ì ‘ AI ë¶„ì„ ì‹œìŠ¤í…œ'ì„ ì§ì ‘ êµ¬í˜„í•˜ë©° ë°ì´í„° ìˆ˜ì§‘ë¶€í„° ëª¨ë¸ í•™ìŠµê¹Œì§€ì˜ ì „ ê³¼ì •ì„ ìˆ˜í–‰í–ˆìŠµë‹ˆë‹¤.\n",
      "ë¶„ë¥˜: Job_Competency (í™•ì‹ ë„: 99.94%)\n",
      "ì„¸ë¶€ í™•ë¥ :\n",
      "  - Communication: 0.02%\n",
      "  - Teamwork_Leadership: 0.01%\n",
      "  - Integrity: 0.01%\n",
      "  - Adaptability: 0.02%\n",
      "  - Job_Competency: 99.94%\n",
      "--------------------------------------------------------------------------------\n",
      "[ë¬¸ì¥ 2]\n",
      "ë‚´ìš©: AI-Hub ë©´ì ‘ ë°ì´í„°ì…‹ì„ ê°€ê³µí•˜ê³ , KoBERT ëª¨ë¸ì„ fine-tuningí•˜ì—¬ ì§€ì›ìì˜ ë‹µë³€ì„ 5ëŒ€ NCS ì—­ëŸ‰(Communication, Integrity, Adaptability, Teamwork, Job Competency) ìœ¼ë¡œ ë¶„ë¥˜í–ˆìŠµë‹ˆë‹¤.\n",
      "ë¶„ë¥˜: Teamwork_Leadership (í™•ì‹ ë„: 84.76%)\n",
      "ì„¸ë¶€ í™•ë¥ :\n",
      "  - Communication: 0.22%\n",
      "  - Teamwork_Leadership: 84.76%\n",
      "  - Integrity: 7.38%\n",
      "  - Adaptability: 1.63%\n",
      "  - Job_Competency: 6.02%\n",
      "--------------------------------------------------------------------------------\n",
      "[ë¬¸ì¥ 3]\n",
      "ë‚´ìš©: ë˜í•œ FastAPIì™€ LangChainì„ ì´ìš©í•´ GPT APIì™€ ì—°ë™í•œ ë©´ì ‘ í”¼ë“œë°± ìë™ ìƒì„± ì‹œìŠ¤í…œì„ ê°œë°œí•˜ë©° AIê°€ ë‹¨ìˆœí•œ ë¶„ì„ ë„êµ¬ê°€ ì•„ë‹Œ ê²½í—˜ì„ ê°œì„ í•˜ëŠ” ì„œë¹„ìŠ¤ê°€ ë  ìˆ˜ ìˆìŒì„ ì‹¤ê°í–ˆìŠµë‹ˆë‹¤.\n",
      "ë¶„ë¥˜: Job_Competency (í™•ì‹ ë„: 93.58%)\n",
      "ì„¸ë¶€ í™•ë¥ :\n",
      "  - Communication: 0.06%\n",
      "  - Teamwork_Leadership: 0.08%\n",
      "  - Integrity: 0.12%\n",
      "  - Adaptability: 6.16%\n",
      "  - Job_Competency: 93.58%\n",
      "--------------------------------------------------------------------------------\n",
      "[ë¬¸ì¥ 4]\n",
      "ë‚´ìš©: ì´ ê²½í—˜ì„ í†µí•´ ë°ì´í„° ë¶„ì„ê³¼ AI ì„œë¹„ìŠ¤ ê¸°íš, ê·¸ë¦¬ê³  ì‚¬ìš©ì ê²½í—˜ì„ ì—°ê²°í•˜ëŠ” ì‹œê°ì„ í‚¤ì› ìŠµë‹ˆë‹¤.\n",
      "ë¶„ë¥˜: Communication (í™•ì‹ ë„: 64.91%)\n",
      "ì„¸ë¶€ í™•ë¥ :\n",
      "  - Communication: 64.91%\n",
      "  - Teamwork_Leadership: 0.34%\n",
      "  - Integrity: 1.68%\n",
      "  - Adaptability: 0.20%\n",
      "  - Job_Competency: 32.87%\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "================================================================================\n",
      "ğŸ“Š ë¶„ì„ ìš”ì•½\n",
      "================================================================================\n",
      "\n",
      "ì˜ë„ë³„ ë¬¸ì¥ ìˆ˜:\n",
      "  Job_Competency: 2ê°œ (50.0%)\n",
      "  Teamwork_Leadership: 1ê°œ (25.0%)\n",
      "  Communication: 1ê°œ (25.0%)\n",
      "\n",
      "í‰ê·  í™•ì‹ ë„: 85.80%\n",
      "\n",
      "================================================================================\n",
      "ğŸ’¡ íŒ:\n",
      "  - ì–‘ìí™” ëª¨ë¸ì€ ì›ë³¸ ëŒ€ë¹„ ì•½ 4ë°° ì‘ê³  2-3ë°° ë¹ ë¦…ë‹ˆë‹¤\n",
      "  - CPUì—ì„œ ìµœì í™”ë˜ì–´ ìˆì–´ GPU ì—†ì´ë„ ë¹ ë¥¸ ì¶”ë¡  ê°€ëŠ¥\n",
      "  - FastAPI ë“± í”„ë¡œë•ì…˜ ë°°í¬ì— ì í•©í•©ë‹ˆë‹¤\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from kobert_transformers import get_tokenizer\n",
    "import re\n",
    "\n",
    "# âš ï¸ ì–‘ìí™” ëª¨ë¸ì€ CPU ì „ìš©!\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "class BertClassifier(nn.Module):\n",
    "    def __init__(self, \n",
    "                 bert,\n",
    "                 hidden_size: int = 768,\n",
    "                 num_classes: int = 5,\n",
    "                 dr_rate: float = 0.3,\n",
    "                 class_weights: torch.Tensor | None = None):\n",
    "        super().__init__()\n",
    "        self.bert = bert\n",
    "        self.dropout = nn.Dropout(p=dr_rate) if dr_rate and dr_rate > 0 else nn.Identity()\n",
    "        self.classifier = nn.Linear(hidden_size, num_classes)\n",
    "        self.loss_fn = nn.CrossEntropyLoss(weight=class_weights) if class_weights is not None else nn.CrossEntropyLoss()\n",
    "    \n",
    "    def forward(self,\n",
    "                input_ids: torch.Tensor,\n",
    "                attention_mask: torch.Tensor | None = None,\n",
    "                token_type_ids: torch.Tensor | None = None,\n",
    "                labels: torch.Tensor | None = None):\n",
    "        \n",
    "        outputs = self.bert(input_ids=input_ids,\n",
    "                            attention_mask=attention_mask,\n",
    "                            token_type_ids=token_type_ids)\n",
    "        \n",
    "        if hasattr(outputs, \"pooler_output\") and outputs.pooler_output is not None:\n",
    "            pooled = outputs.pooler_output\n",
    "        else:\n",
    "            pooled = outputs[0][:, 0]\n",
    "\n",
    "        logits = self.classifier(self.dropout(pooled))\n",
    "\n",
    "        if labels is not None:\n",
    "            loss = self.loss_fn(logits, labels)\n",
    "            return logits, loss\n",
    "        return logits, None\n",
    "\n",
    "def load_quantized_model(model_path, label_map_path):\n",
    "    \"\"\"ì–‘ìí™”ëœ ëª¨ë¸ê³¼ ë¼ë²¨ ë§¤í•‘ ë¡œë“œ (CPU ì „ìš©)\"\"\"\n",
    "    \n",
    "    print(\"âš ï¸  ì–‘ìí™” ëª¨ë¸ì€ CPUì—ì„œë§Œ ì‹¤í–‰ë©ë‹ˆë‹¤.\")\n",
    "    print(\"ğŸ’¡ GPUë¥¼ ì‚¬ìš©í•˜ë ¤ë©´ ì›ë³¸ ëª¨ë¸(model.pt)ì„ ì‚¬ìš©í•˜ì„¸ìš”.\\n\")\n",
    "    \n",
    "    # ë¼ë²¨ ë§¤í•‘ ë¡œë“œ\n",
    "    label_map = {}\n",
    "    with open(label_map_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            idx, label = line.strip().split('\\t')\n",
    "            label_map[int(idx)] = label\n",
    "    \n",
    "    # ì–‘ìí™”ëœ ëª¨ë¸ ì§ì ‘ ë¡œë“œ (ëª¨ë¸ í´ë˜ìŠ¤ ì •ì˜ ë¶ˆí•„ìš”!)\n",
    "    print(\"ì–‘ìí™” ëª¨ë¸ ë¡œë“œ ì¤‘...\")\n",
    "    model = torch.load(model_path, map_location='cpu')\n",
    "    model.eval()\n",
    "    \n",
    "    print(\"âœ“ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ (CPU ëª¨ë“œ)\\n\")\n",
    "    return model, label_map\n",
    "\n",
    "\n",
    "def split_sentences(text):\n",
    "    \"\"\"ë¬¸ë‹¨ì„ ë¬¸ì¥ìœ¼ë¡œ ë¶„ë¦¬\"\"\"\n",
    "    # ì¤„ë°”ê¿ˆ ì œê±° ë° ê³µë°± ì •ë¦¬\n",
    "    text = re.sub(r'\\s+', ' ', text.strip())\n",
    "    \n",
    "    # ë¬¸ì¥ ë¶„ë¦¬ (ë§ˆì¹¨í‘œ, ë¬¼ìŒí‘œ, ëŠë‚Œí‘œ ê¸°ì¤€)\n",
    "    sentences = re.split(r'(?<=[.!?])\\s+', text)\n",
    "    \n",
    "    # ë¹ˆ ë¬¸ì¥ ì œê±°\n",
    "    sentences = [s.strip() for s in sentences if s.strip()]\n",
    "    \n",
    "    return sentences\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_intent(model, tokenizer, sentence, label_map, max_len=502):\n",
    "    \"\"\"ë‹¨ì¼ ë¬¸ì¥ì˜ ì˜ë„ ì˜ˆì¸¡\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # í† í¬ë‚˜ì´ì§•\n",
    "    encoding = tokenizer(\n",
    "        sentence,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        max_length=max_len,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    \n",
    "    # CPUì—ì„œ ì‹¤í–‰ (.to(device) ë¶ˆí•„ìš” - ì´ë¯¸ CPU)\n",
    "    input_ids = encoding['input_ids']\n",
    "    attention_mask = encoding['attention_mask']\n",
    "    token_type_ids = encoding.get('token_type_ids')\n",
    "    \n",
    "    # ì˜ˆì¸¡\n",
    "    logits, _ = model(input_ids, attention_mask, token_type_ids)\n",
    "    probs = torch.softmax(logits, dim=1)\n",
    "    pred_idx = torch.argmax(probs, dim=1).item()\n",
    "    confidence = probs[0][pred_idx].item()\n",
    "    \n",
    "    return label_map[pred_idx], confidence, probs[0].numpy()\n",
    "\n",
    "\n",
    "def analyze_paragraph(model, tokenizer, paragraph, label_map):\n",
    "    \"\"\"ë¬¸ë‹¨ ì „ì²´ ë¶„ì„\"\"\"\n",
    "    sentences = split_sentences(paragraph)\n",
    "    \n",
    "    print(\"=\" * 80)\n",
    "    print(\"ğŸ“ ë¬¸ë‹¨ ë¶„ì„ ê²°ê³¼\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"\\nì´ {len(sentences)}ê°œì˜ ë¬¸ì¥ì´ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤.\\n\")\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for i, sentence in enumerate(sentences, 1):\n",
    "        intent, confidence, probs = predict_intent(model, tokenizer, sentence, label_map)\n",
    "        results.append({\n",
    "            'sentence_num': i,\n",
    "            'sentence': sentence,\n",
    "            'intent': intent,\n",
    "            'confidence': confidence,\n",
    "            'probabilities': probs\n",
    "        })\n",
    "        \n",
    "        print(f\"[ë¬¸ì¥ {i}]\")\n",
    "        print(f\"ë‚´ìš©: {sentence}\")\n",
    "        print(f\"ë¶„ë¥˜: {intent} (í™•ì‹ ë„: {confidence:.2%})\")\n",
    "        \n",
    "        # ëª¨ë“  í´ë˜ìŠ¤ë³„ í™•ë¥  ì¶œë ¥\n",
    "        print(\"ì„¸ë¶€ í™•ë¥ :\")\n",
    "        for idx, prob in enumerate(probs):\n",
    "            print(f\"  - {label_map[idx]}: {prob:.2%}\")\n",
    "        print(\"-\" * 80)\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "def print_summary(results):\n",
    "    \"\"\"ìš”ì•½ í†µê³„ ì¶œë ¥\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"ğŸ“Š ë¶„ì„ ìš”ì•½\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    intent_counts = {}\n",
    "    for result in results:\n",
    "        intent = result['intent']\n",
    "        intent_counts[intent] = intent_counts.get(intent, 0) + 1\n",
    "    \n",
    "    print(\"\\nì˜ë„ë³„ ë¬¸ì¥ ìˆ˜:\")\n",
    "    for intent, count in sorted(intent_counts.items(), key=lambda x: x[1], reverse=True):\n",
    "        percentage = (count / len(results)) * 100\n",
    "        print(f\"  {intent}: {count}ê°œ ({percentage:.1f}%)\")\n",
    "    \n",
    "    avg_confidence = sum(r['confidence'] for r in results) / len(results)\n",
    "    print(f\"\\ní‰ê·  í™•ì‹ ë„: {avg_confidence:.2%}\")\n",
    "\n",
    "\n",
    "# ë©”ì¸ ì‹¤í–‰ ì½”ë“œ\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"=\"*80)\n",
    "    print(\"ğŸš€ ì–‘ìí™” KoBERT ëª¨ë¸ ì¶”ë¡  (CPU ìµœì í™”)\")\n",
    "    print(\"=\"*80)\n",
    "    print()\n",
    "    \n",
    "    # ëª¨ë¸ ë° í† í¬ë‚˜ì´ì € ë¡œë“œ\n",
    "    MODEL_PATH = \"/home/j-k13b204/S13P31B204/model_test/kobert_intent_model/quantize/model_quantized.pt\"\n",
    "    LABEL_MAP_PATH = \"/home/j-k13b204/S13P31B204/model_test/kobert_intent_model/quantize/label_map.txt\"\n",
    "    \n",
    "    print(\"ëª¨ë¸ì„ ë¡œë“œí•˜ëŠ” ì¤‘...\")\n",
    "    tokenizer = get_tokenizer()\n",
    "    model, label_map = load_quantized_model(MODEL_PATH, LABEL_MAP_PATH)\n",
    "    \n",
    "    # ë¶„ì„í•  ë¬¸ë‹¨\n",
    "    sentence = \"\"\"\n",
    "    ìµœê·¼ì—ëŠ” 'VR ê¸°ë°˜ ë©´ì ‘ AI ë¶„ì„ ì‹œìŠ¤í…œ'ì„ ì§ì ‘ êµ¬í˜„í•˜ë©°\n",
    "    ë°ì´í„° ìˆ˜ì§‘ë¶€í„° ëª¨ë¸ í•™ìŠµê¹Œì§€ì˜ ì „ ê³¼ì •ì„ ìˆ˜í–‰í–ˆìŠµë‹ˆë‹¤.\n",
    "    AI-Hub ë©´ì ‘ ë°ì´í„°ì…‹ì„ ê°€ê³µí•˜ê³ , KoBERT ëª¨ë¸ì„ fine-tuningí•˜ì—¬\n",
    "    ì§€ì›ìì˜ ë‹µë³€ì„ 5ëŒ€ NCS ì—­ëŸ‰(Communication, Integrity, Adaptability, Teamwork, Job Competency) ìœ¼ë¡œ ë¶„ë¥˜í–ˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "    ë˜í•œ FastAPIì™€ LangChainì„ ì´ìš©í•´ GPT APIì™€ ì—°ë™í•œ ë©´ì ‘ í”¼ë“œë°± ìë™ ìƒì„± ì‹œìŠ¤í…œì„ ê°œë°œí•˜ë©°\n",
    "    AIê°€ ë‹¨ìˆœí•œ ë¶„ì„ ë„êµ¬ê°€ ì•„ë‹Œ ê²½í—˜ì„ ê°œì„ í•˜ëŠ” ì„œë¹„ìŠ¤ê°€ ë  ìˆ˜ ìˆìŒì„ ì‹¤ê°í–ˆìŠµë‹ˆë‹¤.\n",
    "    ì´ ê²½í—˜ì„ í†µí•´ ë°ì´í„° ë¶„ì„ê³¼ AI ì„œë¹„ìŠ¤ ê¸°íš, ê·¸ë¦¬ê³  ì‚¬ìš©ì ê²½í—˜ì„ ì—°ê²°í•˜ëŠ” ì‹œê°ì„ í‚¤ì› ìŠµë‹ˆë‹¤.\n",
    "    \"\"\"\n",
    "    \n",
    "    # ë¶„ì„ ì‹¤í–‰\n",
    "    results = analyze_paragraph(model, tokenizer, sentence, label_map)\n",
    "    \n",
    "    # ìš”ì•½ ì¶œë ¥\n",
    "    print_summary(results)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"ğŸ’¡ íŒ:\")\n",
    "    print(\"  - ì–‘ìí™” ëª¨ë¸ì€ ì›ë³¸ ëŒ€ë¹„ ì•½ 4ë°° ì‘ê³  2-3ë°° ë¹ ë¦…ë‹ˆë‹¤\")\n",
    "    print(\"  - CPUì—ì„œ ìµœì í™”ë˜ì–´ ìˆì–´ GPU ì—†ì´ë„ ë¹ ë¥¸ ì¶”ë¡  ê°€ëŠ¥\")\n",
    "    print(\"  - FastAPI ë“± í”„ë¡œë•ì…˜ ë°°í¬ì— ì í•©í•©ë‹ˆë‹¤\")\n",
    "    print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
